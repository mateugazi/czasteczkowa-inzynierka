{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import (StratifiedKFold, KFold,\n",
    "                                     cross_val_score, train_test_split)\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "N_SPLITS = 2\n",
    "RANDOM_STATE = 148260"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadCSV(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "def LoadCSV_BACE(path, regression = False):\n",
    "    df = pd.read_csv(path)\n",
    "    df.drop_duplicates('mol')\n",
    "    df = df.dropna()\n",
    "    df.drop(['CID', 'canvasUID'], axis=1, inplace=True)\n",
    "    if regression:\n",
    "        df['Target'] = df['pIC50']\n",
    "        df.drop('Class', axis=1, inplace=True)\n",
    "        df.drop('pIC50', axis=1, inplace=True)\n",
    "    else:\n",
    "        df['Target'] = df['Class']\n",
    "        df.drop('Class', axis=1, inplace=True)\n",
    "        df.drop('pIC50', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def split_data_BACE(df):\n",
    "    X = df.drop(['Target', 'mol'], axis=1)\n",
    "\n",
    "    X_train = X[X['Model'] == 'Train']\n",
    "    X_test = X[X['Model'] == 'Test']\n",
    "    X_valid = X[X['Model'] == 'Valid']\n",
    "\n",
    "    y = df[['Target', 'Model']]\n",
    "\n",
    "    y_train = y[y['Model'] == 'Train']\n",
    "    y_test = y[y['Model'] == 'Test']\n",
    "    y_valid = y[y['Model'] == 'Valid']\n",
    "    \n",
    "    X_train.drop('Model', axis=1, inplace=True)\n",
    "    X_test.drop('Model', axis=1, inplace=True)\n",
    "    X_valid.drop('Model', axis=1, inplace=True)\n",
    "    y_train.drop('Model', axis=1, inplace=True)\n",
    "    y_test.drop('Model', axis=1, inplace=True)\n",
    "    y_valid.drop('Model', axis=1, inplace=True)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = LoadCSV_BACE(r\"C:\\Users\\wojci\\Documents\\GitHub\\czasteczkowa-inzynierka\\experiments\\BACE\\bace.csv\", regression=True)\n",
    "df_classification = LoadCSV_BACE(r\"C:\\Users\\wojci\\Documents\\GitHub\\czasteczkowa-inzynierka\\experiments\\BACE\\bace.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class, y_train_class, X_test_class, y_test_class, X_valid_class, y_valid_class = split_data_BACE(df_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regre, y_train_regre, X_test_regre, y_test_regre, X_valid_regre, y_valid_regre = split_data_BACE(df_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1513, 592)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_regre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 589)\n",
      "(1265, 589)\n",
      "(45, 589)\n",
      "0.13\n",
      "0.84\n",
      "0.03\n"
     ]
    }
   ],
   "source": [
    "print(X_train_class.shape)\n",
    "print(X_test_class.shape)\n",
    "print(X_valid_class.shape)\n",
    "print(f\"{round(X_train_class.shape[0] / df_classification.shape[0], 2)}\")\n",
    "print(f\"{round(X_test_class.shape[0] / df_classification.shape[0], 2)}\")\n",
    "print(f\"{round(X_valid_class.shape[0] / df_classification.shape[0], 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>HBA</th>\n",
       "      <th>HBD</th>\n",
       "      <th>RB</th>\n",
       "      <th>HeavyAtomCount</th>\n",
       "      <th>ChiralCenterCount</th>\n",
       "      <th>ChiralCenterCountAllPossible</th>\n",
       "      <th>RingCount</th>\n",
       "      <th>PSA</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE5 (PEOE5)</th>\n",
       "      <th>PEOE6 (PEOE6)</th>\n",
       "      <th>PEOE7 (PEOE7)</th>\n",
       "      <th>PEOE8 (PEOE8)</th>\n",
       "      <th>PEOE9 (PEOE9)</th>\n",
       "      <th>PEOE10 (PEOE10)</th>\n",
       "      <th>PEOE11 (PEOE11)</th>\n",
       "      <th>PEOE12 (PEOE12)</th>\n",
       "      <th>PEOE13 (PEOE13)</th>\n",
       "      <th>PEOE14 (PEOE14)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431.56979</td>\n",
       "      <td>4.4014</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>77.239998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.205711</td>\n",
       "      <td>78.640335</td>\n",
       "      <td>226.85541</td>\n",
       "      <td>107.43491</td>\n",
       "      <td>37.133846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.980170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>657.81073</td>\n",
       "      <td>2.6412</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>124.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.817162</td>\n",
       "      <td>47.171600</td>\n",
       "      <td>365.67694</td>\n",
       "      <td>174.07675</td>\n",
       "      <td>34.923889</td>\n",
       "      <td>7.980170</td>\n",
       "      <td>24.148668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.663788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>591.74091</td>\n",
       "      <td>2.5499</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>125.860000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.365707</td>\n",
       "      <td>47.941147</td>\n",
       "      <td>192.40652</td>\n",
       "      <td>255.75255</td>\n",
       "      <td>23.654478</td>\n",
       "      <td>0.230159</td>\n",
       "      <td>15.879790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.663788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>591.67828</td>\n",
       "      <td>3.1680</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>123.840000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.657166</td>\n",
       "      <td>37.954151</td>\n",
       "      <td>194.35304</td>\n",
       "      <td>202.76335</td>\n",
       "      <td>36.498634</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>8.188327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.385181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629.71283</td>\n",
       "      <td>3.5086</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>116.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.945702</td>\n",
       "      <td>39.361153</td>\n",
       "      <td>179.71288</td>\n",
       "      <td>220.46130</td>\n",
       "      <td>23.654478</td>\n",
       "      <td>0.230159</td>\n",
       "      <td>15.879790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.100143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 589 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MW   AlogP  HBA  HBD  RB  HeavyAtomCount  ChiralCenterCount   \n",
       "0  431.56979  4.4014    3    2   5              32                  2  \\\n",
       "1  657.81073  2.6412    5    4  16              47                  6   \n",
       "2  591.74091  2.5499    4    3  11              42                  2   \n",
       "3  591.67828  3.1680    4    3  12              40                  4   \n",
       "4  629.71283  3.5086    3    3  11              44                  2   \n",
       "\n",
       "   ChiralCenterCountAllPossible  RingCount         PSA  ...  PEOE5 (PEOE5)   \n",
       "0                             2          4   77.239998  ...            0.0  \\\n",
       "1                             6          4  124.580000  ...            0.0   \n",
       "2                             3          5  125.860000  ...            0.0   \n",
       "3                             5          3  123.840000  ...            0.0   \n",
       "4                             3          5  116.630000  ...            0.0   \n",
       "\n",
       "   PEOE6 (PEOE6)  PEOE7 (PEOE7)  PEOE8 (PEOE8)  PEOE9 (PEOE9)   \n",
       "0      53.205711      78.640335      226.85541      107.43491  \\\n",
       "1      73.817162      47.171600      365.67694      174.07675   \n",
       "2      70.365707      47.941147      192.40652      255.75255   \n",
       "3      56.657166      37.954151      194.35304      202.76335   \n",
       "4      78.945702      39.361153      179.71288      220.46130   \n",
       "\n",
       "   PEOE10 (PEOE10)  PEOE11 (PEOE11)  PEOE12 (PEOE12)  PEOE13 (PEOE13)   \n",
       "0        37.133846         0.000000         7.980170              0.0  \\\n",
       "1        34.923889         7.980170        24.148668              0.0   \n",
       "2        23.654478         0.230159        15.879790              0.0   \n",
       "3        36.498634         0.980913         8.188327              0.0   \n",
       "4        23.654478         0.230159        15.879790              0.0   \n",
       "\n",
       "   PEOE14 (PEOE14)  \n",
       "0         0.000000  \n",
       "1        24.663788  \n",
       "2        24.663788  \n",
       "3        26.385181  \n",
       "4        26.100143  \n",
       "\n",
       "[5 rows x 589 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_regre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>HBA</th>\n",
       "      <th>HBD</th>\n",
       "      <th>RB</th>\n",
       "      <th>HeavyAtomCount</th>\n",
       "      <th>ChiralCenterCount</th>\n",
       "      <th>ChiralCenterCountAllPossible</th>\n",
       "      <th>RingCount</th>\n",
       "      <th>PSA</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE5 (PEOE5)</th>\n",
       "      <th>PEOE6 (PEOE6)</th>\n",
       "      <th>PEOE7 (PEOE7)</th>\n",
       "      <th>PEOE8 (PEOE8)</th>\n",
       "      <th>PEOE9 (PEOE9)</th>\n",
       "      <th>PEOE10 (PEOE10)</th>\n",
       "      <th>PEOE11 (PEOE11)</th>\n",
       "      <th>PEOE12 (PEOE12)</th>\n",
       "      <th>PEOE13 (PEOE13)</th>\n",
       "      <th>PEOE14 (PEOE14)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>403.55969</td>\n",
       "      <td>5.7644</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>68.010002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.122887</td>\n",
       "      <td>46.316166</td>\n",
       "      <td>247.78938</td>\n",
       "      <td>90.395477</td>\n",
       "      <td>37.133846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.980170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>615.73102</td>\n",
       "      <td>1.4277</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>135.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.960800</td>\n",
       "      <td>38.272877</td>\n",
       "      <td>304.05246</td>\n",
       "      <td>152.161880</td>\n",
       "      <td>34.923889</td>\n",
       "      <td>7.980170</td>\n",
       "      <td>32.336994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.663788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>498.65250</td>\n",
       "      <td>3.3870</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>88.059998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.077168</td>\n",
       "      <td>49.532818</td>\n",
       "      <td>332.80533</td>\n",
       "      <td>84.453911</td>\n",
       "      <td>34.435734</td>\n",
       "      <td>15.387257</td>\n",
       "      <td>8.188327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.663788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>484.62601</td>\n",
       "      <td>2.9008</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>88.059998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.077168</td>\n",
       "      <td>45.445873</td>\n",
       "      <td>299.93298</td>\n",
       "      <td>95.216072</td>\n",
       "      <td>34.435734</td>\n",
       "      <td>15.387257</td>\n",
       "      <td>8.188327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.663788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>639.75238</td>\n",
       "      <td>3.8163</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>117.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.863713</td>\n",
       "      <td>37.771442</td>\n",
       "      <td>88.147522</td>\n",
       "      <td>261.31158</td>\n",
       "      <td>250.925540</td>\n",
       "      <td>35.014828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.571255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.663788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 589 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MW   AlogP  HBA  HBD  RB  HeavyAtomCount  ChiralCenterCount   \n",
       "248  403.55969  5.7644    2    2   7              30                  0  \\\n",
       "249  615.73102  1.4277    5    5  13              44                  0   \n",
       "250  498.65250  3.3870    4    3   9              36                  0   \n",
       "251  484.62601  2.9008    4    3   9              35                  0   \n",
       "252  639.75238  3.8163    6    3  17              46                  0   \n",
       "\n",
       "     ChiralCenterCountAllPossible  RingCount         PSA  ...  PEOE5 (PEOE5)   \n",
       "248                             1          3   68.010002  ...       0.000000  \\\n",
       "249                             7          4  135.580000  ...       0.000000   \n",
       "250                             3          4   88.059998  ...       0.000000   \n",
       "251                             3          4   88.059998  ...       0.000000   \n",
       "252                             2          3  117.070000  ...      11.863713   \n",
       "\n",
       "     PEOE6 (PEOE6)  PEOE7 (PEOE7)  PEOE8 (PEOE8)  PEOE9 (PEOE9)   \n",
       "248      84.122887      46.316166      247.78938      90.395477  \\\n",
       "249      67.960800      38.272877      304.05246     152.161880   \n",
       "250      48.077168      49.532818      332.80533      84.453911   \n",
       "251      48.077168      45.445873      299.93298      95.216072   \n",
       "252      37.771442      88.147522      261.31158     250.925540   \n",
       "\n",
       "     PEOE10 (PEOE10)  PEOE11 (PEOE11)  PEOE12 (PEOE12)  PEOE13 (PEOE13)   \n",
       "248        37.133846         0.000000         7.980170              0.0  \\\n",
       "249        34.923889         7.980170        32.336994              0.0   \n",
       "250        34.435734        15.387257         8.188327              0.0   \n",
       "251        34.435734        15.387257         8.188327              0.0   \n",
       "252        35.014828         0.000000        23.571255              0.0   \n",
       "\n",
       "     PEOE14 (PEOE14)  \n",
       "248         0.000000  \n",
       "249        24.663788  \n",
       "250        24.663788  \n",
       "251        24.663788  \n",
       "252        24.663788  \n",
       "\n",
       "[5 rows x 589 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_regre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>HBA</th>\n",
       "      <th>HBD</th>\n",
       "      <th>RB</th>\n",
       "      <th>HeavyAtomCount</th>\n",
       "      <th>ChiralCenterCount</th>\n",
       "      <th>ChiralCenterCountAllPossible</th>\n",
       "      <th>RingCount</th>\n",
       "      <th>PSA</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE6 (PEOE6)</th>\n",
       "      <th>PEOE7 (PEOE7)</th>\n",
       "      <th>PEOE8 (PEOE8)</th>\n",
       "      <th>PEOE9 (PEOE9)</th>\n",
       "      <th>PEOE10 (PEOE10)</th>\n",
       "      <th>PEOE11 (PEOE11)</th>\n",
       "      <th>PEOE12 (PEOE12)</th>\n",
       "      <th>PEOE13 (PEOE13)</th>\n",
       "      <th>PEOE14 (PEOE14)</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>479.661988</td>\n",
       "      <td>3.177080</td>\n",
       "      <td>3.732981</td>\n",
       "      <td>2.001322</td>\n",
       "      <td>8.049570</td>\n",
       "      <td>34.089227</td>\n",
       "      <td>0.522802</td>\n",
       "      <td>2.317250</td>\n",
       "      <td>3.769993</td>\n",
       "      <td>99.842829</td>\n",
       "      <td>...</td>\n",
       "      <td>52.348846</td>\n",
       "      <td>48.763740</td>\n",
       "      <td>181.835580</td>\n",
       "      <td>148.442348</td>\n",
       "      <td>30.371697</td>\n",
       "      <td>3.488650</td>\n",
       "      <td>11.740560</td>\n",
       "      <td>1.239762</td>\n",
       "      <td>14.387597</td>\n",
       "      <td>0.456709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>122.083053</td>\n",
       "      <td>1.396633</td>\n",
       "      <td>1.444778</td>\n",
       "      <td>1.629343</td>\n",
       "      <td>4.741135</td>\n",
       "      <td>8.520088</td>\n",
       "      <td>1.162539</td>\n",
       "      <td>1.612558</td>\n",
       "      <td>0.877390</td>\n",
       "      <td>34.973718</td>\n",
       "      <td>...</td>\n",
       "      <td>25.993800</td>\n",
       "      <td>18.201519</td>\n",
       "      <td>99.717702</td>\n",
       "      <td>60.548833</td>\n",
       "      <td>12.162452</td>\n",
       "      <td>5.148336</td>\n",
       "      <td>9.073406</td>\n",
       "      <td>3.293804</td>\n",
       "      <td>13.329890</td>\n",
       "      <td>0.498287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>138.187000</td>\n",
       "      <td>-4.361100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.610001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.551821</td>\n",
       "      <td>1.916970</td>\n",
       "      <td>-5.536391</td>\n",
       "      <td>-2.216191</td>\n",
       "      <td>-7.286308</td>\n",
       "      <td>-6.106466</td>\n",
       "      <td>-7.379991</td>\n",
       "      <td>-1.273524</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>389.331300</td>\n",
       "      <td>2.335500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.050003</td>\n",
       "      <td>...</td>\n",
       "      <td>34.319988</td>\n",
       "      <td>36.547150</td>\n",
       "      <td>102.233770</td>\n",
       "      <td>102.510450</td>\n",
       "      <td>20.132990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.980170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>463.628300</td>\n",
       "      <td>3.171300</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>95.040001</td>\n",
       "      <td>...</td>\n",
       "      <td>51.479984</td>\n",
       "      <td>47.624382</td>\n",
       "      <td>171.917220</td>\n",
       "      <td>140.683620</td>\n",
       "      <td>30.107586</td>\n",
       "      <td>0.550130</td>\n",
       "      <td>8.188327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.710098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>564.639530</td>\n",
       "      <td>4.015500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>116.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>66.553795</td>\n",
       "      <td>58.844093</td>\n",
       "      <td>253.679080</td>\n",
       "      <td>185.659260</td>\n",
       "      <td>37.133846</td>\n",
       "      <td>7.980170</td>\n",
       "      <td>15.879790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.663788</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1350.473300</td>\n",
       "      <td>7.617400</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>525.060000</td>\n",
       "      <td>...</td>\n",
       "      <td>161.342860</td>\n",
       "      <td>124.272730</td>\n",
       "      <td>865.473330</td>\n",
       "      <td>378.516270</td>\n",
       "      <td>121.671900</td>\n",
       "      <td>29.823961</td>\n",
       "      <td>80.218018</td>\n",
       "      <td>16.681131</td>\n",
       "      <td>61.659470</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                MW        AlogP          HBA          HBD           RB   \n",
       "count  1513.000000  1513.000000  1513.000000  1513.000000  1513.000000  \\\n",
       "mean    479.661988     3.177080     3.732981     2.001322     8.049570   \n",
       "std     122.083053     1.396633     1.444778     1.629343     4.741135   \n",
       "min     138.187000    -4.361100     0.000000     0.000000     0.000000   \n",
       "25%     389.331300     2.335500     3.000000     0.000000     4.000000   \n",
       "50%     463.628300     3.171300     4.000000     2.000000     7.000000   \n",
       "75%     564.639530     4.015500     4.000000     3.000000    11.000000   \n",
       "max    1350.473300     7.617400    12.000000    15.000000    40.000000   \n",
       "\n",
       "       HeavyAtomCount  ChiralCenterCount  ChiralCenterCountAllPossible   \n",
       "count     1513.000000        1513.000000                   1513.000000  \\\n",
       "mean        34.089227           0.522802                      2.317250   \n",
       "std          8.520088           1.162539                      1.612558   \n",
       "min         10.000000           0.000000                      0.000000   \n",
       "25%         28.000000           0.000000                      1.000000   \n",
       "50%         33.000000           0.000000                      2.000000   \n",
       "75%         40.000000           1.000000                      3.000000   \n",
       "max         97.000000          10.000000                     12.000000   \n",
       "\n",
       "         RingCount          PSA  ...  PEOE6 (PEOE6)  PEOE7 (PEOE7)   \n",
       "count  1513.000000  1513.000000  ...    1513.000000    1513.000000  \\\n",
       "mean      3.769993    99.842829  ...      52.348846      48.763740   \n",
       "std       0.877390    34.973718  ...      25.993800      18.201519   \n",
       "min       0.000000    16.610001  ...       0.000000      -3.551821   \n",
       "25%       3.000000    77.050003  ...      34.319988      36.547150   \n",
       "50%       4.000000    95.040001  ...      51.479984      47.624382   \n",
       "75%       4.000000   116.630000  ...      66.553795      58.844093   \n",
       "max       7.000000   525.060000  ...     161.342860     124.272730   \n",
       "\n",
       "       PEOE8 (PEOE8)  PEOE9 (PEOE9)  PEOE10 (PEOE10)  PEOE11 (PEOE11)   \n",
       "count    1513.000000    1513.000000      1513.000000      1513.000000  \\\n",
       "mean      181.835580     148.442348        30.371697         3.488650   \n",
       "std        99.717702      60.548833        12.162452         5.148336   \n",
       "min         1.916970      -5.536391        -2.216191        -7.286308   \n",
       "25%       102.233770     102.510450        20.132990         0.000000   \n",
       "50%       171.917220     140.683620        30.107586         0.550130   \n",
       "75%       253.679080     185.659260        37.133846         7.980170   \n",
       "max       865.473330     378.516270       121.671900        29.823961   \n",
       "\n",
       "       PEOE12 (PEOE12)  PEOE13 (PEOE13)  PEOE14 (PEOE14)       Target  \n",
       "count      1513.000000      1513.000000      1513.000000  1513.000000  \n",
       "mean         11.740560         1.239762        14.387597     0.456709  \n",
       "std           9.073406         3.293804        13.329890     0.498287  \n",
       "min          -6.106466        -7.379991        -1.273524     0.000000  \n",
       "25%           7.980170         0.000000         0.000000     0.000000  \n",
       "50%           8.188327         0.000000        21.710098     0.000000  \n",
       "75%          15.879790         0.000000        24.663788     1.000000  \n",
       "max          80.218018        16.681131        61.659470     1.000000  \n",
       "\n",
       "[8 rows x 590 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf(X, y, n_estimators, max_depth, min_samples_split, min_samples_leaf, regression=False):\n",
    "    if regression:\n",
    "        name = \"RandomForestRegressor\"\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "        cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        name = \"RandomForestClassifier\"\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'roc_auc'\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    mean_accuracy = scores.mean()\n",
    "    return (f\"{name}-{n_estimators}-{max_depth}-{min_samples_split}-{min_samples_leaf}; {mean_accuracy:.4f}\")\n",
    "\n",
    "def run_lr(X, y, C, penalty, solver, regression=False):\n",
    "    if regression:\n",
    "        name = \"LinearRegression\"\n",
    "        model = LinearRegression()\n",
    "        cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        name = \"LogisticRegression\"\n",
    "        model = LogisticRegression(C=C, penalty=penalty, solver=solver)\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'roc_auc'\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    mean_accuracy = scores.mean()\n",
    "    return (f\"{name}-{C}-{penalty}-{solver}; {mean_accuracy:.4f}\")\n",
    "\n",
    "def run_nn(X, y, hidden_layer_sizes, activation, alpha, max_iter, regression=False):\n",
    "    if regression:\n",
    "        name = \"MLPRegressor\"\n",
    "        model = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, activation=activation, alpha=alpha, max_iter=max_iter)\n",
    "        cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        name = \"MLPClassifier\"\n",
    "        model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, alpha=alpha, max_iter=max_iter)\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'roc_auc'\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    mean_accuracy = scores.mean()\n",
    "    return (f\"{name}-{hidden_layer_sizes}-{activation}-{alpha}-{max_iter}; {mean_accuracy:.4f}\")\n",
    "\n",
    "def run_gb(X, y, n_estimators, learning_rate, regression=False):\n",
    "    if regression:\n",
    "        name = \"GradientBoostingRegressor\"\n",
    "        model = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "        cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        name = \"GradientBoostingClassifier\"\n",
    "        model = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'roc_auc'\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    mean_accuracy = scores.mean()\n",
    "    return (f\"{name}-{n_estimators}-{learning_rate}; {mean_accuracy:.4f}\")\n",
    "\n",
    "def run_svm(X, y, c, d, e, regression=False):\n",
    "    if regression:\n",
    "        name = \"SVR\"\n",
    "        model = SVR(C=c, degree=d, epsilon=e, kernel=\"poly\")\n",
    "        cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        name = \"SVC\"\n",
    "        model = SVC(C=c, degree=d, kernel=\"poly\") ### Epsilon is ignored\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'roc_auc'\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    mean_accuracy = scores.mean()\n",
    "    return (f\"{name}-{c}-{d}-{e}; {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(X, y, regression=False):\n",
    "    results = []\n",
    "\n",
    "    print(\"Run\")\n",
    "\n",
    "    #### -----\n",
    "\n",
    "    param_grid_rf={\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    param_combinations = list(product(*param_grid_rf.values()))\n",
    "    for combination in param_combinations:\n",
    "        n, m, s, l = combination\n",
    "        results.append(run_rf(X, y, n, m, s, l, regression))\n",
    "        print(results[-1])\n",
    "    ### -----\n",
    "\n",
    "    param_grid_lr = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    }\n",
    "    if regression:\n",
    "        param_grid_lr = {\n",
    "            'C': [0.001],\n",
    "            'penalty': ['l1'],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    param_combinations = list(product(*param_grid_lr.values()))\n",
    "    for combination in param_combinations:\n",
    "        C, p, s = combination\n",
    "        results.append(run_lr(X, y, C, p, s, regression))\n",
    "        print(results[-1])\n",
    "    ### -----\n",
    "\n",
    "    param_grid_mlp = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'max_iter': [200, 500, 1000]\n",
    "    }\n",
    "    param_combinations = list(product(*param_grid_mlp.values()))\n",
    "    for combination in param_combinations:\n",
    "        h, ac, a, i = combination\n",
    "        results.append(run_nn(X, y, h, ac, a, i, regression))\n",
    "        print(results[-1])\n",
    "    ### -----\n",
    "\n",
    "    param_grid_gb={\n",
    "        'n_estimators': [10, 100, 200], \n",
    "        'learning_rate': [0.1,0.5,1.0,2.0]\n",
    "    }\n",
    "    param_combinations = list(product(*param_grid_gb.values()))\n",
    "    for combination in param_combinations:\n",
    "        n, lr = combination\n",
    "        results.append(run_gb(X, y, n, lr, regression))\n",
    "        print(results[-1])\n",
    "    ### -----\n",
    "    \n",
    "    param_grid_svm = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'degree': [2, 3, 4, 5],\n",
    "        'epsilon': [\"no epsilon\"]\n",
    "    }\n",
    "    \n",
    "    if regression:\n",
    "        param_grid_svm = {\n",
    "            'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'degree': [2, 3, 4, 5],\n",
    "            'epsilon': [0.01, 0.1, 1]\n",
    "        }\n",
    "        param_combinations = list(product(*param_grid_svm.values()))\n",
    "        for combination in param_combinations:\n",
    "            c, d, e = combination\n",
    "            results.append(run_svm(X, y, c, d, e, regression))\n",
    "            print(results[-1])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_configured(regression=False, pca=False):\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    if regression:\n",
    "        X = sc.fit_transform(pd.concat([X_train_regre, X_test_regre]))\n",
    "        y = pd.concat([y_train_regre, y_test_regre])\n",
    "        \n",
    "    else:\n",
    "        X = sc.fit_transform(pd.concat([X_train_class, X_test_class]))\n",
    "        y = pd.concat([y_train_class, y_test_class])\n",
    "\n",
    "    if pca:\n",
    "        pca = PCA(n_components=0.95)\n",
    "        X = pca.fit_transform(X)\n",
    "\n",
    "    results = run_all(X, y, regression=regression)\n",
    "\n",
    "    csv_path = \"BACE_comparison_results_\"\n",
    "    if regression: csv_path += \"regression\" \n",
    "    else: csv_path += \"classification\"\n",
    "    csv_path += \"_sc\"\n",
    "    if pca: csv_path += \"pca\"\n",
    "    csv_path += \"_svm.csv\"\n",
    "\n",
    "    data_tuples = [tuple(item.split('; ')) for item in results]\n",
    "    df = pd.DataFrame(data_tuples, columns=['Classifier', 'Accuracy'])\n",
    "    df.to_csv(csv_path)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run\n",
      "RandomForestClassifier-50-None-2-1; 0.8680\n",
      "RandomForestClassifier-50-None-2-2; 0.8710\n",
      "RandomForestClassifier-50-None-2-4; 0.8641\n",
      "RandomForestClassifier-50-None-5-1; 0.8728\n",
      "RandomForestClassifier-50-None-5-2; 0.8710\n",
      "RandomForestClassifier-50-None-5-4; 0.8691\n",
      "RandomForestClassifier-50-None-10-1; 0.8685\n",
      "RandomForestClassifier-50-None-10-2; 0.8731\n",
      "RandomForestClassifier-50-None-10-4; 0.8648\n",
      "RandomForestClassifier-50-10-2-1; 0.8755\n",
      "RandomForestClassifier-50-10-2-2; 0.8703\n",
      "RandomForestClassifier-50-10-2-4; 0.8679\n",
      "RandomForestClassifier-50-10-5-1; 0.8733\n",
      "RandomForestClassifier-50-10-5-2; 0.8727\n",
      "RandomForestClassifier-50-10-5-4; 0.8713\n",
      "RandomForestClassifier-50-10-10-1; 0.8681\n",
      "RandomForestClassifier-50-10-10-2; 0.8735\n",
      "RandomForestClassifier-50-10-10-4; 0.8687\n",
      "RandomForestClassifier-50-20-2-1; 0.8679\n",
      "RandomForestClassifier-50-20-2-2; 0.8676\n",
      "RandomForestClassifier-50-20-2-4; 0.8681\n",
      "RandomForestClassifier-50-20-5-1; 0.8721\n",
      "RandomForestClassifier-50-20-5-2; 0.8689\n",
      "RandomForestClassifier-50-20-5-4; 0.8675\n",
      "RandomForestClassifier-50-20-10-1; 0.8696\n",
      "RandomForestClassifier-50-20-10-2; 0.8738\n",
      "RandomForestClassifier-50-20-10-4; 0.8710\n",
      "RandomForestClassifier-100-None-2-1; 0.8703\n",
      "RandomForestClassifier-100-None-2-2; 0.8729\n",
      "RandomForestClassifier-100-None-2-4; 0.8715\n",
      "RandomForestClassifier-100-None-5-1; 0.8731\n",
      "RandomForestClassifier-100-None-5-2; 0.8753\n",
      "RandomForestClassifier-100-None-5-4; 0.8689\n",
      "RandomForestClassifier-100-None-10-1; 0.8725\n",
      "RandomForestClassifier-100-None-10-2; 0.8735\n",
      "RandomForestClassifier-100-None-10-4; 0.8686\n",
      "RandomForestClassifier-100-10-2-1; 0.8738\n",
      "RandomForestClassifier-100-10-2-2; 0.8746\n",
      "RandomForestClassifier-100-10-2-4; 0.8692\n",
      "RandomForestClassifier-100-10-5-1; 0.8723\n",
      "RandomForestClassifier-100-10-5-2; 0.8715\n",
      "RandomForestClassifier-100-10-5-4; 0.8704\n",
      "RandomForestClassifier-100-10-10-1; 0.8733\n",
      "RandomForestClassifier-100-10-10-2; 0.8711\n",
      "RandomForestClassifier-100-10-10-4; 0.8683\n",
      "RandomForestClassifier-100-20-2-1; 0.8733\n",
      "RandomForestClassifier-100-20-2-2; 0.8724\n",
      "RandomForestClassifier-100-20-2-4; 0.8691\n",
      "RandomForestClassifier-100-20-5-1; 0.8716\n",
      "RandomForestClassifier-100-20-5-2; 0.8718\n",
      "RandomForestClassifier-100-20-5-4; 0.8687\n",
      "RandomForestClassifier-100-20-10-1; 0.8714\n",
      "RandomForestClassifier-100-20-10-2; 0.8725\n",
      "RandomForestClassifier-100-20-10-4; 0.8712\n",
      "LogisticRegression-0.001-l1-liblinear; 0.5000\n",
      "LogisticRegression-0.001-l1-saga; 0.5000\n",
      "LogisticRegression-0.001-l2-liblinear; 0.8180\n",
      "LogisticRegression-0.001-l2-saga; 0.8178\n",
      "LogisticRegression-0.01-l1-liblinear; 0.7568\n",
      "LogisticRegression-0.01-l1-saga; 0.7582\n",
      "LogisticRegression-0.01-l2-liblinear; 0.8491\n",
      "LogisticRegression-0.01-l2-saga; 0.8490\n",
      "LogisticRegression-0.1-l1-liblinear; 0.8442\n",
      "LogisticRegression-0.1-l1-saga; 0.8459\n",
      "LogisticRegression-0.1-l2-liblinear; 0.8569\n",
      "LogisticRegression-0.1-l2-saga; 0.8567\n",
      "LogisticRegression-1-l1-liblinear; 0.8521\n",
      "LogisticRegression-1-l1-saga; 0.8569\n",
      "LogisticRegression-1-l2-liblinear; 0.8474\n",
      "LogisticRegression-1-l2-saga; 0.8570\n",
      "LogisticRegression-10-l1-liblinear; 0.8195\n",
      "LogisticRegression-10-l1-saga; 0.8570\n",
      "LogisticRegression-10-l2-liblinear; 0.8270\n",
      "LogisticRegression-10-l2-saga; 0.8569\n",
      "LogisticRegression-100-l1-liblinear; 0.7857\n",
      "LogisticRegression-100-l1-saga; 0.8571\n",
      "LogisticRegression-100-l2-liblinear; 0.8070\n",
      "LogisticRegression-100-l2-saga; 0.8568\n",
      "MLPClassifier-(50,)-relu-0.0001-200; 0.8561\n",
      "MLPClassifier-(50,)-relu-0.0001-500; 0.8453\n",
      "MLPClassifier-(50,)-relu-0.0001-1000; 0.8455\n",
      "MLPClassifier-(50,)-relu-0.001-200; 0.8509\n",
      "MLPClassifier-(50,)-relu-0.001-500; 0.8435\n",
      "MLPClassifier-(50,)-relu-0.001-1000; 0.8456\n",
      "MLPClassifier-(50,)-relu-0.01-200; 0.8553\n",
      "MLPClassifier-(50,)-relu-0.01-500; 0.8468\n",
      "MLPClassifier-(50,)-relu-0.01-1000; 0.8487\n",
      "MLPClassifier-(50,)-tanh-0.0001-200; 0.8506\n",
      "MLPClassifier-(50,)-tanh-0.0001-500; 0.8467\n",
      "MLPClassifier-(50,)-tanh-0.0001-1000; 0.8440\n",
      "MLPClassifier-(50,)-tanh-0.001-200; 0.8504\n",
      "MLPClassifier-(50,)-tanh-0.001-500; 0.8496\n",
      "MLPClassifier-(50,)-tanh-0.001-1000; 0.8447\n",
      "MLPClassifier-(50,)-tanh-0.01-200; 0.8573\n",
      "MLPClassifier-(50,)-tanh-0.01-500; 0.8551\n",
      "MLPClassifier-(50,)-tanh-0.01-1000; 0.8534\n",
      "MLPClassifier-(100,)-relu-0.0001-200; 0.8477\n",
      "MLPClassifier-(100,)-relu-0.0001-500; 0.8402\n",
      "MLPClassifier-(100,)-relu-0.0001-1000; 0.8495\n",
      "MLPClassifier-(100,)-relu-0.001-200; 0.8527\n",
      "MLPClassifier-(100,)-relu-0.001-500; 0.8480\n",
      "MLPClassifier-(100,)-relu-0.001-1000; 0.8482\n",
      "MLPClassifier-(100,)-relu-0.01-200; 0.8565\n",
      "MLPClassifier-(100,)-relu-0.01-500; 0.8473\n",
      "MLPClassifier-(100,)-relu-0.01-1000; 0.8486\n",
      "MLPClassifier-(100,)-tanh-0.0001-200; 0.8499\n",
      "MLPClassifier-(100,)-tanh-0.0001-500; 0.8482\n",
      "MLPClassifier-(100,)-tanh-0.0001-1000; 0.8485\n",
      "MLPClassifier-(100,)-tanh-0.001-200; 0.8519\n",
      "MLPClassifier-(100,)-tanh-0.001-500; 0.8519\n",
      "MLPClassifier-(100,)-tanh-0.001-1000; 0.8472\n",
      "MLPClassifier-(100,)-tanh-0.01-200; 0.8547\n",
      "MLPClassifier-(100,)-tanh-0.01-500; 0.8515\n",
      "MLPClassifier-(100,)-tanh-0.01-1000; 0.8532\n",
      "MLPClassifier-(50, 50)-relu-0.0001-200; 0.8490\n",
      "MLPClassifier-(50, 50)-relu-0.0001-500; 0.8427\n",
      "MLPClassifier-(50, 50)-relu-0.0001-1000; 0.8446\n",
      "MLPClassifier-(50, 50)-relu-0.001-200; 0.8456\n",
      "MLPClassifier-(50, 50)-relu-0.001-500; 0.8411\n",
      "MLPClassifier-(50, 50)-relu-0.001-1000; 0.8406\n",
      "MLPClassifier-(50, 50)-relu-0.01-200; 0.8491\n",
      "MLPClassifier-(50, 50)-relu-0.01-500; 0.8470\n",
      "MLPClassifier-(50, 50)-relu-0.01-1000; 0.8431\n",
      "MLPClassifier-(50, 50)-tanh-0.0001-200; 0.8425\n",
      "MLPClassifier-(50, 50)-tanh-0.0001-500; 0.8425\n",
      "MLPClassifier-(50, 50)-tanh-0.0001-1000; 0.8431\n",
      "MLPClassifier-(50, 50)-tanh-0.001-200; 0.8380\n",
      "MLPClassifier-(50, 50)-tanh-0.001-500; 0.8393\n",
      "MLPClassifier-(50, 50)-tanh-0.001-1000; 0.8399\n",
      "MLPClassifier-(50, 50)-tanh-0.01-200; 0.8404\n",
      "MLPClassifier-(50, 50)-tanh-0.01-500; 0.8368\n",
      "MLPClassifier-(50, 50)-tanh-0.01-1000; 0.8452\n",
      "GradientBoostingClassifier-10-0.1; 0.8455\n",
      "GradientBoostingClassifier-10-0.5; 0.8531\n",
      "GradientBoostingClassifier-10-1.0; 0.8002\n",
      "GradientBoostingClassifier-10-2.0; 0.7282\n",
      "GradientBoostingClassifier-100-0.1; 0.8722\n",
      "GradientBoostingClassifier-100-0.5; 0.8605\n",
      "GradientBoostingClassifier-100-1.0; 0.8377\n",
      "GradientBoostingClassifier-100-2.0; 0.7124\n",
      "GradientBoostingClassifier-200-0.1; 0.8721\n",
      "GradientBoostingClassifier-200-0.5; 0.8582\n",
      "GradientBoostingClassifier-200-1.0; 0.8519\n",
      "GradientBoostingClassifier-200-2.0; 0.7649\n",
      "Run\n",
      "RandomForestClassifier-50-None-2-1; 0.8447\n",
      "RandomForestClassifier-50-None-2-2; 0.8555\n",
      "RandomForestClassifier-50-None-2-4; 0.8602\n",
      "RandomForestClassifier-50-None-5-1; 0.8598\n",
      "RandomForestClassifier-50-None-5-2; 0.8575\n",
      "RandomForestClassifier-50-None-5-4; 0.8602\n",
      "RandomForestClassifier-50-None-10-1; 0.8586\n",
      "RandomForestClassifier-50-None-10-2; 0.8546\n",
      "RandomForestClassifier-50-None-10-4; 0.8590\n",
      "RandomForestClassifier-50-10-2-1; 0.8537\n",
      "RandomForestClassifier-50-10-2-2; 0.8537\n",
      "RandomForestClassifier-50-10-2-4; 0.8548\n",
      "RandomForestClassifier-50-10-5-1; 0.8585\n",
      "RandomForestClassifier-50-10-5-2; 0.8552\n",
      "RandomForestClassifier-50-10-5-4; 0.8487\n",
      "RandomForestClassifier-50-10-10-1; 0.8541\n",
      "RandomForestClassifier-50-10-10-2; 0.8594\n",
      "RandomForestClassifier-50-10-10-4; 0.8548\n",
      "RandomForestClassifier-50-20-2-1; 0.8546\n",
      "RandomForestClassifier-50-20-2-2; 0.8528\n",
      "RandomForestClassifier-50-20-2-4; 0.8614\n",
      "RandomForestClassifier-50-20-5-1; 0.8505\n",
      "RandomForestClassifier-50-20-5-2; 0.8508\n",
      "RandomForestClassifier-50-20-5-4; 0.8528\n",
      "RandomForestClassifier-50-20-10-1; 0.8585\n",
      "RandomForestClassifier-50-20-10-2; 0.8526\n",
      "RandomForestClassifier-50-20-10-4; 0.8539\n",
      "RandomForestClassifier-100-None-2-1; 0.8582\n",
      "RandomForestClassifier-100-None-2-2; 0.8594\n",
      "RandomForestClassifier-100-None-2-4; 0.8635\n",
      "RandomForestClassifier-100-None-5-1; 0.8593\n",
      "RandomForestClassifier-100-None-5-2; 0.8576\n",
      "RandomForestClassifier-100-None-5-4; 0.8624\n",
      "RandomForestClassifier-100-None-10-1; 0.8597\n",
      "RandomForestClassifier-100-None-10-2; 0.8637\n",
      "RandomForestClassifier-100-None-10-4; 0.8631\n",
      "RandomForestClassifier-100-10-2-1; 0.8633\n",
      "RandomForestClassifier-100-10-2-2; 0.8624\n",
      "RandomForestClassifier-100-10-2-4; 0.8596\n",
      "RandomForestClassifier-100-10-5-1; 0.8618\n",
      "RandomForestClassifier-100-10-5-2; 0.8630\n",
      "RandomForestClassifier-100-10-5-4; 0.8581\n",
      "RandomForestClassifier-100-10-10-1; 0.8639\n",
      "RandomForestClassifier-100-10-10-2; 0.8575\n",
      "RandomForestClassifier-100-10-10-4; 0.8645\n",
      "RandomForestClassifier-100-20-2-1; 0.8568\n",
      "RandomForestClassifier-100-20-2-2; 0.8602\n",
      "RandomForestClassifier-100-20-2-4; 0.8555\n",
      "RandomForestClassifier-100-20-5-1; 0.8584\n",
      "RandomForestClassifier-100-20-5-2; 0.8619\n",
      "RandomForestClassifier-100-20-5-4; 0.8618\n",
      "RandomForestClassifier-100-20-10-1; 0.8597\n",
      "RandomForestClassifier-100-20-10-2; 0.8601\n",
      "RandomForestClassifier-100-20-10-4; 0.8593\n",
      "LogisticRegression-0.001-l1-liblinear; 0.5772\n",
      "LogisticRegression-0.001-l1-saga; 0.5772\n",
      "LogisticRegression-0.001-l2-liblinear; 0.8139\n",
      "LogisticRegression-0.001-l2-saga; 0.8137\n",
      "LogisticRegression-0.01-l1-liblinear; 0.7945\n",
      "LogisticRegression-0.01-l1-saga; 0.7965\n",
      "LogisticRegression-0.01-l2-liblinear; 0.8368\n",
      "LogisticRegression-0.01-l2-saga; 0.8368\n",
      "LogisticRegression-0.1-l1-liblinear; 0.8366\n",
      "LogisticRegression-0.1-l1-saga; 0.8370\n",
      "LogisticRegression-0.1-l2-liblinear; 0.8366\n",
      "LogisticRegression-0.1-l2-saga; 0.8379\n",
      "LogisticRegression-1-l1-liblinear; 0.8357\n",
      "LogisticRegression-1-l1-saga; 0.8377\n",
      "LogisticRegression-1-l2-liblinear; 0.8334\n",
      "LogisticRegression-1-l2-saga; 0.8372\n",
      "LogisticRegression-10-l1-liblinear; 0.8326\n",
      "LogisticRegression-10-l1-saga; 0.8371\n",
      "LogisticRegression-10-l2-liblinear; 0.8323\n",
      "LogisticRegression-10-l2-saga; 0.8373\n",
      "LogisticRegression-100-l1-liblinear; 0.8317\n",
      "LogisticRegression-100-l1-saga; 0.8371\n",
      "LogisticRegression-100-l2-liblinear; 0.8317\n",
      "LogisticRegression-100-l2-saga; 0.8372\n",
      "MLPClassifier-(50,)-relu-0.0001-200; 0.8595\n",
      "MLPClassifier-(50,)-relu-0.0001-500; 0.8520\n",
      "MLPClassifier-(50,)-relu-0.0001-1000; 0.8440\n",
      "MLPClassifier-(50,)-relu-0.001-200; 0.8536\n",
      "MLPClassifier-(50,)-relu-0.001-500; 0.8474\n",
      "MLPClassifier-(50,)-relu-0.001-1000; 0.8435\n",
      "MLPClassifier-(50,)-relu-0.01-200; 0.8581\n",
      "MLPClassifier-(50,)-relu-0.01-500; 0.8444\n",
      "MLPClassifier-(50,)-relu-0.01-1000; 0.8369\n",
      "MLPClassifier-(50,)-tanh-0.0001-200; 0.8644\n",
      "MLPClassifier-(50,)-tanh-0.0001-500; 0.8572\n",
      "MLPClassifier-(50,)-tanh-0.0001-1000; 0.8479\n",
      "MLPClassifier-(50,)-tanh-0.001-200; 0.8642\n",
      "MLPClassifier-(50,)-tanh-0.001-500; 0.8565\n",
      "MLPClassifier-(50,)-tanh-0.001-1000; 0.8473\n",
      "MLPClassifier-(50,)-tanh-0.01-200; 0.8578\n",
      "MLPClassifier-(50,)-tanh-0.01-500; 0.8498\n",
      "MLPClassifier-(50,)-tanh-0.01-1000; 0.8513\n",
      "MLPClassifier-(100,)-relu-0.0001-200; 0.8534\n",
      "MLPClassifier-(100,)-relu-0.0001-500; 0.8513\n",
      "MLPClassifier-(100,)-relu-0.0001-1000; 0.8424\n",
      "MLPClassifier-(100,)-relu-0.001-200; 0.8574\n",
      "MLPClassifier-(100,)-relu-0.001-500; 0.8463\n",
      "MLPClassifier-(100,)-relu-0.001-1000; 0.8513\n",
      "MLPClassifier-(100,)-relu-0.01-200; 0.8601\n",
      "MLPClassifier-(100,)-relu-0.01-500; 0.8505\n",
      "MLPClassifier-(100,)-relu-0.01-1000; 0.8450\n",
      "MLPClassifier-(100,)-tanh-0.0001-200; 0.8610\n",
      "MLPClassifier-(100,)-tanh-0.0001-500; 0.8585\n",
      "MLPClassifier-(100,)-tanh-0.0001-1000; 0.8586\n",
      "MLPClassifier-(100,)-tanh-0.001-200; 0.8557\n",
      "MLPClassifier-(100,)-tanh-0.001-500; 0.8567\n",
      "MLPClassifier-(100,)-tanh-0.001-1000; 0.8596\n",
      "MLPClassifier-(100,)-tanh-0.01-200; 0.8589\n",
      "MLPClassifier-(100,)-tanh-0.01-500; 0.8555\n",
      "MLPClassifier-(100,)-tanh-0.01-1000; 0.8556\n",
      "MLPClassifier-(50, 50)-relu-0.0001-200; 0.8512\n",
      "MLPClassifier-(50, 50)-relu-0.0001-500; 0.8524\n",
      "MLPClassifier-(50, 50)-relu-0.0001-1000; 0.8430\n",
      "MLPClassifier-(50, 50)-relu-0.001-200; 0.8482\n",
      "MLPClassifier-(50, 50)-relu-0.001-500; 0.8516\n",
      "MLPClassifier-(50, 50)-relu-0.001-1000; 0.8458\n",
      "MLPClassifier-(50, 50)-relu-0.01-200; 0.8489\n",
      "MLPClassifier-(50, 50)-relu-0.01-500; 0.8419\n",
      "MLPClassifier-(50, 50)-relu-0.01-1000; 0.8397\n",
      "MLPClassifier-(50, 50)-tanh-0.0001-200; 0.8405\n",
      "MLPClassifier-(50, 50)-tanh-0.0001-500; 0.8355\n",
      "MLPClassifier-(50, 50)-tanh-0.0001-1000; 0.8499\n",
      "MLPClassifier-(50, 50)-tanh-0.001-200; 0.8416\n",
      "MLPClassifier-(50, 50)-tanh-0.001-500; 0.8424\n",
      "MLPClassifier-(50, 50)-tanh-0.001-1000; 0.8533\n",
      "MLPClassifier-(50, 50)-tanh-0.01-200; 0.8431\n",
      "MLPClassifier-(50, 50)-tanh-0.01-500; 0.8432\n",
      "MLPClassifier-(50, 50)-tanh-0.01-1000; 0.8549\n",
      "GradientBoostingClassifier-10-0.1; 0.8289\n",
      "GradientBoostingClassifier-10-0.5; 0.8343\n",
      "GradientBoostingClassifier-10-1.0; 0.8012\n",
      "GradientBoostingClassifier-10-2.0; 0.7364\n",
      "GradientBoostingClassifier-100-0.1; 0.8529\n",
      "GradientBoostingClassifier-100-0.5; 0.8456\n",
      "GradientBoostingClassifier-100-1.0; 0.8338\n",
      "GradientBoostingClassifier-100-2.0; 0.6625\n",
      "GradientBoostingClassifier-200-0.1; 0.8514\n",
      "GradientBoostingClassifier-200-0.5; 0.8409\n",
      "GradientBoostingClassifier-200-1.0; 0.8320\n",
      "GradientBoostingClassifier-200-2.0; 0.6639\n",
      "Run\n",
      "RandomForestRegressor-50-None-2-1; -0.6142\n",
      "RandomForestRegressor-50-None-2-2; -0.6044\n",
      "RandomForestRegressor-50-None-2-4; -0.6046\n",
      "RandomForestRegressor-50-None-5-1; -0.6021\n",
      "RandomForestRegressor-50-None-5-2; -0.5921\n",
      "RandomForestRegressor-50-None-5-4; -0.6079\n",
      "RandomForestRegressor-50-None-10-1; -0.6015\n",
      "RandomForestRegressor-50-None-10-2; -0.5964\n",
      "RandomForestRegressor-50-None-10-4; -0.6112\n",
      "RandomForestRegressor-50-10-2-1; -0.5967\n",
      "RandomForestRegressor-50-10-2-2; -0.5965\n",
      "RandomForestRegressor-50-10-2-4; -0.6128\n",
      "RandomForestRegressor-50-10-5-1; -0.6077\n",
      "RandomForestRegressor-50-10-5-2; -0.6091\n",
      "RandomForestRegressor-50-10-5-4; -0.6087\n",
      "RandomForestRegressor-50-10-10-1; -0.6113\n",
      "RandomForestRegressor-50-10-10-2; -0.6056\n",
      "RandomForestRegressor-50-10-10-4; -0.6085\n",
      "RandomForestRegressor-50-20-2-1; -0.6132\n",
      "RandomForestRegressor-50-20-2-2; -0.5946\n",
      "RandomForestRegressor-50-20-2-4; -0.6148\n",
      "RandomForestRegressor-50-20-5-1; -0.5982\n",
      "RandomForestRegressor-50-20-5-2; -0.6016\n",
      "RandomForestRegressor-50-20-5-4; -0.6211\n",
      "RandomForestRegressor-50-20-10-1; -0.6001\n",
      "RandomForestRegressor-50-20-10-2; -0.5950\n",
      "RandomForestRegressor-50-20-10-4; -0.6021\n",
      "RandomForestRegressor-100-None-2-1; -0.5914\n",
      "RandomForestRegressor-100-None-2-2; -0.5942\n",
      "RandomForestRegressor-100-None-2-4; -0.5989\n",
      "RandomForestRegressor-100-None-5-1; -0.5986\n",
      "RandomForestRegressor-100-None-5-2; -0.6032\n",
      "RandomForestRegressor-100-None-5-4; -0.5982\n",
      "RandomForestRegressor-100-None-10-1; -0.5975\n",
      "RandomForestRegressor-100-None-10-2; -0.5961\n",
      "RandomForestRegressor-100-None-10-4; -0.6037\n",
      "RandomForestRegressor-100-10-2-1; -0.5988\n",
      "RandomForestRegressor-100-10-2-2; -0.5934\n",
      "RandomForestRegressor-100-10-2-4; -0.6009\n",
      "RandomForestRegressor-100-10-5-1; -0.5905\n",
      "RandomForestRegressor-100-10-5-2; -0.5903\n",
      "RandomForestRegressor-100-10-5-4; -0.5988\n",
      "RandomForestRegressor-100-10-10-1; -0.6010\n",
      "RandomForestRegressor-100-10-10-2; -0.5957\n",
      "RandomForestRegressor-100-10-10-4; -0.6011\n",
      "RandomForestRegressor-100-20-2-1; -0.5975\n",
      "RandomForestRegressor-100-20-2-2; -0.5902\n",
      "RandomForestRegressor-100-20-2-4; -0.5972\n",
      "RandomForestRegressor-100-20-5-1; -0.6059\n",
      "RandomForestRegressor-100-20-5-2; -0.6011\n",
      "RandomForestRegressor-100-20-5-4; -0.6114\n",
      "RandomForestRegressor-100-20-10-1; -0.5970\n",
      "RandomForestRegressor-100-20-10-2; -0.6027\n",
      "RandomForestRegressor-100-20-10-4; -0.6014\n",
      "LinearRegression-0.001-l1-liblinear; -368538926254156414976.0000\n",
      "MLPRegressor-(50,)-relu-0.0001-200; -1.0045\n",
      "MLPRegressor-(50,)-relu-0.0001-500; -1.3188\n",
      "MLPRegressor-(50,)-relu-0.0001-1000; -1.5147\n",
      "MLPRegressor-(50,)-relu-0.001-200; -1.5259\n",
      "MLPRegressor-(50,)-relu-0.001-500; -1.2654\n",
      "MLPRegressor-(50,)-relu-0.001-1000; -1.4346\n",
      "MLPRegressor-(50,)-relu-0.01-200; -1.1729\n",
      "MLPRegressor-(50,)-relu-0.01-500; -1.2864\n",
      "MLPRegressor-(50,)-relu-0.01-1000; -1.2842\n",
      "MLPRegressor-(50,)-tanh-0.0001-200; -3.2200\n",
      "MLPRegressor-(50,)-tanh-0.0001-500; -3.9959\n",
      "MLPRegressor-(50,)-tanh-0.0001-1000; -3.6232\n",
      "MLPRegressor-(50,)-tanh-0.001-200; -3.7489\n",
      "MLPRegressor-(50,)-tanh-0.001-500; -3.8976\n",
      "MLPRegressor-(50,)-tanh-0.001-1000; -3.5756\n",
      "MLPRegressor-(50,)-tanh-0.01-200; -3.6599\n",
      "MLPRegressor-(50,)-tanh-0.01-500; -3.2999\n",
      "MLPRegressor-(50,)-tanh-0.01-1000; -3.7952\n",
      "MLPRegressor-(100,)-relu-0.0001-200; -1.3309\n",
      "MLPRegressor-(100,)-relu-0.0001-500; -1.0303\n",
      "MLPRegressor-(100,)-relu-0.0001-1000; -1.0708\n",
      "MLPRegressor-(100,)-relu-0.001-200; -1.1006\n",
      "MLPRegressor-(100,)-relu-0.001-500; -1.1621\n",
      "MLPRegressor-(100,)-relu-0.001-1000; -1.2609\n",
      "MLPRegressor-(100,)-relu-0.01-200; -1.2086\n",
      "MLPRegressor-(100,)-relu-0.01-500; -1.1244\n",
      "MLPRegressor-(100,)-relu-0.01-1000; -1.1514\n",
      "MLPRegressor-(100,)-tanh-0.0001-200; -4.1591\n",
      "MLPRegressor-(100,)-tanh-0.0001-500; -3.7849\n",
      "MLPRegressor-(100,)-tanh-0.0001-1000; -4.1795\n",
      "MLPRegressor-(100,)-tanh-0.001-200; -4.0982\n",
      "MLPRegressor-(100,)-tanh-0.001-500; -4.2333\n",
      "MLPRegressor-(100,)-tanh-0.001-1000; -3.8064\n",
      "MLPRegressor-(100,)-tanh-0.01-200; -3.4861\n",
      "MLPRegressor-(100,)-tanh-0.01-500; -3.8186\n",
      "MLPRegressor-(100,)-tanh-0.01-1000; -4.2167\n",
      "MLPRegressor-(50, 50)-relu-0.0001-200; -0.8218\n",
      "MLPRegressor-(50, 50)-relu-0.0001-500; -0.8550\n",
      "MLPRegressor-(50, 50)-relu-0.0001-1000; -1.0556\n",
      "MLPRegressor-(50, 50)-relu-0.001-200; -0.8877\n",
      "MLPRegressor-(50, 50)-relu-0.001-500; -0.9060\n",
      "MLPRegressor-(50, 50)-relu-0.001-1000; -0.8781\n",
      "MLPRegressor-(50, 50)-relu-0.01-200; -0.8406\n",
      "MLPRegressor-(50, 50)-relu-0.01-500; -0.9226\n",
      "MLPRegressor-(50, 50)-relu-0.01-1000; -0.9493\n",
      "MLPRegressor-(50, 50)-tanh-0.0001-200; -3.3155\n",
      "MLPRegressor-(50, 50)-tanh-0.0001-500; -2.9993\n",
      "MLPRegressor-(50, 50)-tanh-0.0001-1000; -3.1777\n",
      "MLPRegressor-(50, 50)-tanh-0.001-200; -2.7759\n",
      "MLPRegressor-(50, 50)-tanh-0.001-500; -3.2549\n",
      "MLPRegressor-(50, 50)-tanh-0.001-1000; -3.3064\n",
      "MLPRegressor-(50, 50)-tanh-0.01-200; -3.1266\n",
      "MLPRegressor-(50, 50)-tanh-0.01-500; -3.2071\n",
      "MLPRegressor-(50, 50)-tanh-0.01-1000; -3.0023\n",
      "GradientBoostingRegressor-10-0.1; -0.9357\n",
      "GradientBoostingRegressor-10-0.5; -0.7007\n",
      "GradientBoostingRegressor-10-1.0; -0.9984\n",
      "GradientBoostingRegressor-10-2.0; -2.3373\n",
      "GradientBoostingRegressor-100-0.1; -0.5928\n",
      "GradientBoostingRegressor-100-0.5; -0.7139\n",
      "GradientBoostingRegressor-100-1.0; -1.1814\n",
      "GradientBoostingRegressor-100-2.0; -3.1180\n",
      "GradientBoostingRegressor-200-0.1; -0.5740\n",
      "GradientBoostingRegressor-200-0.5; -0.7263\n",
      "GradientBoostingRegressor-200-1.0; -1.1892\n",
      "GradientBoostingRegressor-200-2.0; -2.7330\n",
      "Eval\n",
      "\n",
      "SVR-0.01-2-0.01; -1.6973\n",
      "Eval\n",
      "\n",
      "SVR-0.01-2-0.1; -1.6928\n",
      "Eval\n",
      "\n",
      "SVR-0.01-2-1; -1.6682\n",
      "Eval\n",
      "\n",
      "SVR-0.01-3-0.01; -1.5864\n",
      "Eval\n",
      "\n",
      "SVR-0.01-3-0.1; -1.5874\n",
      "Eval\n",
      "\n",
      "SVR-0.01-3-1; -1.5734\n",
      "Eval\n",
      "\n",
      "SVR-0.01-4-0.01; -1.6982\n",
      "Eval\n",
      "\n",
      "SVR-0.01-4-0.1; -1.6945\n",
      "Eval\n",
      "\n",
      "SVR-0.01-4-1; -1.6554\n",
      "Eval\n",
      "\n",
      "SVR-0.01-5-0.01; -1.7818\n",
      "Eval\n",
      "\n",
      "SVR-0.01-5-0.1; -1.7957\n",
      "Eval\n",
      "\n",
      "SVR-0.01-5-1; -1.8949\n",
      "Eval\n",
      "\n",
      "SVR-0.1-2-0.01; -1.2708\n",
      "Eval\n",
      "\n",
      "SVR-0.1-2-0.1; -1.2666\n",
      "Eval\n",
      "\n",
      "SVR-0.1-2-1; -1.3620\n",
      "Eval\n",
      "\n",
      "SVR-0.1-3-0.01; -1.1501\n",
      "Eval\n",
      "\n",
      "SVR-0.1-3-0.1; -1.1458\n",
      "Eval\n",
      "\n",
      "SVR-0.1-3-1; -1.2295\n",
      "Eval\n",
      "\n",
      "SVR-0.1-4-0.01; -1.5797\n",
      "Eval\n",
      "\n",
      "SVR-0.1-4-0.1; -1.5422\n",
      "Eval\n",
      "\n",
      "SVR-0.1-4-1; -1.4420\n",
      "Eval\n",
      "\n",
      "SVR-0.1-5-0.01; -2.1779\n",
      "Eval\n",
      "\n",
      "SVR-0.1-5-0.1; -2.0922\n",
      "Eval\n",
      "\n",
      "SVR-0.1-5-1; -1.6222\n",
      "Eval\n",
      "\n",
      "SVR-1-2-0.01; -0.8525\n",
      "Eval\n",
      "\n",
      "SVR-1-2-0.1; -0.8535\n",
      "Eval\n",
      "\n",
      "SVR-1-2-1; -0.9805\n",
      "Eval\n",
      "\n",
      "SVR-1-3-0.01; -0.8809\n",
      "Eval\n",
      "\n",
      "SVR-1-3-0.1; -0.8523\n",
      "Eval\n",
      "\n",
      "SVR-1-3-1; -0.9731\n",
      "Eval\n",
      "\n",
      "SVR-1-4-0.01; -1.9286\n",
      "Eval\n",
      "\n",
      "SVR-1-4-0.1; -1.9038\n",
      "Eval\n",
      "\n",
      "SVR-1-4-1; -1.7898\n",
      "Eval\n",
      "\n",
      "SVR-1-5-0.01; -4.7581\n",
      "Eval\n",
      "\n",
      "SVR-1-5-0.1; -5.2239\n",
      "Eval\n",
      "\n",
      "SVR-1-5-1; -5.5209\n",
      "Eval\n",
      "\n",
      "SVR-10-2-0.01; -0.9166\n",
      "Eval\n",
      "\n",
      "SVR-10-2-0.1; -0.8983\n",
      "Eval\n",
      "\n",
      "SVR-10-2-1; -0.9549\n",
      "Eval\n",
      "\n",
      "SVR-10-3-0.01; -1.0618\n",
      "Eval\n",
      "\n",
      "SVR-10-3-0.1; -1.0108\n",
      "Eval\n",
      "\n",
      "SVR-10-3-1; -1.0842\n",
      "Eval\n",
      "\n",
      "SVR-10-4-0.01; -3.4595\n",
      "Eval\n",
      "\n",
      "SVR-10-4-0.1; -3.1198\n",
      "Eval\n",
      "\n",
      "SVR-10-4-1; -2.5930\n",
      "Eval\n",
      "\n",
      "SVR-10-5-0.01; -9.7572\n",
      "Eval\n",
      "\n",
      "SVR-10-5-0.1; -9.4419\n",
      "Eval\n",
      "\n",
      "SVR-10-5-1; -13.4841\n",
      "Eval\n",
      "\n",
      "SVR-100-2-0.01; -1.7852\n",
      "Eval\n",
      "\n",
      "SVR-100-2-0.1; -1.6020\n",
      "Eval\n",
      "\n",
      "SVR-100-2-1; -1.0044\n",
      "Eval\n",
      "\n",
      "SVR-100-3-0.01; -2.1046\n",
      "Eval\n",
      "\n",
      "SVR-100-3-0.1; -1.7391\n",
      "Eval\n",
      "\n",
      "SVR-100-3-1; -1.3411\n",
      "Eval\n",
      "\n",
      "SVR-100-4-0.01; -18.9242\n",
      "Eval\n",
      "\n",
      "SVR-100-4-0.1; -16.2051\n",
      "Eval\n",
      "\n",
      "SVR-100-4-1; -2.8258\n",
      "Eval\n",
      "\n",
      "SVR-100-5-0.01; -77.8449\n",
      "Eval\n",
      "\n",
      "SVR-100-5-0.1; -55.1553\n",
      "Eval\n",
      "\n",
      "SVR-100-5-1; -37.7524\n",
      "Eval\n",
      "\n",
      "SVR-1000-2-0.01; -2.9487\n",
      "Eval\n",
      "\n",
      "SVR-1000-2-0.1; -2.4346\n",
      "Eval\n",
      "\n",
      "SVR-1000-2-1; -1.0032\n",
      "Eval\n",
      "\n",
      "SVR-1000-3-0.01; -2.4520\n",
      "Eval\n",
      "\n",
      "SVR-1000-3-0.1; -2.2094\n",
      "Eval\n",
      "\n",
      "SVR-1000-3-1; -1.3397\n",
      "Eval\n",
      "\n",
      "SVR-1000-4-0.01; -21.8317\n",
      "Eval\n",
      "\n",
      "SVR-1000-4-0.1; -17.0694\n",
      "Eval\n",
      "\n",
      "SVR-1000-4-1; -3.0351\n",
      "Eval\n",
      "\n",
      "SVR-1000-5-0.01; -132.3980\n",
      "Eval\n",
      "\n",
      "SVR-1000-5-0.1; -82.9864\n",
      "Eval\n",
      "\n",
      "SVR-1000-5-1; -38.4162\n",
      "Run\n",
      "RandomForestRegressor-50-None-2-1; -0.7196\n",
      "RandomForestRegressor-50-None-2-2; -0.7231\n",
      "RandomForestRegressor-50-None-2-4; -0.7088\n",
      "RandomForestRegressor-50-None-5-1; -0.7119\n",
      "RandomForestRegressor-50-None-5-2; -0.7363\n",
      "RandomForestRegressor-50-None-5-4; -0.7335\n",
      "RandomForestRegressor-50-None-10-1; -0.7437\n",
      "RandomForestRegressor-50-None-10-2; -0.7329\n",
      "RandomForestRegressor-50-None-10-4; -0.7244\n",
      "RandomForestRegressor-50-10-2-1; -0.7286\n",
      "RandomForestRegressor-50-10-2-2; -0.7454\n",
      "RandomForestRegressor-50-10-2-4; -0.7247\n",
      "RandomForestRegressor-50-10-5-1; -0.7078\n",
      "RandomForestRegressor-50-10-5-2; -0.7229\n",
      "RandomForestRegressor-50-10-5-4; -0.7187\n",
      "RandomForestRegressor-50-10-10-1; -0.7300\n",
      "RandomForestRegressor-50-10-10-2; -0.7256\n",
      "RandomForestRegressor-50-10-10-4; -0.7285\n",
      "RandomForestRegressor-50-20-2-1; -0.7082\n",
      "RandomForestRegressor-50-20-2-2; -0.7198\n",
      "RandomForestRegressor-50-20-2-4; -0.7221\n",
      "RandomForestRegressor-50-20-5-1; -0.7055\n",
      "RandomForestRegressor-50-20-5-2; -0.7180\n",
      "RandomForestRegressor-50-20-5-4; -0.7063\n",
      "RandomForestRegressor-50-20-10-1; -0.7155\n",
      "RandomForestRegressor-50-20-10-2; -0.7190\n",
      "RandomForestRegressor-50-20-10-4; -0.7183\n",
      "RandomForestRegressor-100-None-2-1; -0.7079\n",
      "RandomForestRegressor-100-None-2-2; -0.7070\n",
      "RandomForestRegressor-100-None-2-4; -0.7122\n",
      "RandomForestRegressor-100-None-5-1; -0.7129\n",
      "RandomForestRegressor-100-None-5-2; -0.7014\n",
      "RandomForestRegressor-100-None-5-4; -0.7113\n",
      "RandomForestRegressor-100-None-10-1; -0.7299\n",
      "RandomForestRegressor-100-None-10-2; -0.7148\n",
      "RandomForestRegressor-100-None-10-4; -0.7149\n",
      "RandomForestRegressor-100-10-2-1; -0.7110\n",
      "RandomForestRegressor-100-10-2-2; -0.7048\n",
      "RandomForestRegressor-100-10-2-4; -0.7204\n",
      "RandomForestRegressor-100-10-5-1; -0.7079\n",
      "RandomForestRegressor-100-10-5-2; -0.7121\n",
      "RandomForestRegressor-100-10-5-4; -0.7160\n",
      "RandomForestRegressor-100-10-10-1; -0.7192\n",
      "RandomForestRegressor-100-10-10-2; -0.7128\n",
      "RandomForestRegressor-100-10-10-4; -0.7120\n",
      "RandomForestRegressor-100-20-2-1; -0.7086\n",
      "RandomForestRegressor-100-20-2-2; -0.7058\n",
      "RandomForestRegressor-100-20-2-4; -0.7113\n",
      "RandomForestRegressor-100-20-5-1; -0.7245\n",
      "RandomForestRegressor-100-20-5-2; -0.7141\n",
      "RandomForestRegressor-100-20-5-4; -0.7046\n",
      "RandomForestRegressor-100-20-10-1; -0.7172\n",
      "RandomForestRegressor-100-20-10-2; -0.7084\n",
      "RandomForestRegressor-100-20-10-4; -0.7261\n",
      "LinearRegression-0.001-l1-liblinear; -1.0418\n",
      "MLPRegressor-(50,)-relu-0.0001-200; -0.9814\n",
      "MLPRegressor-(50,)-relu-0.0001-500; -0.9988\n",
      "MLPRegressor-(50,)-relu-0.0001-1000; -1.2318\n",
      "MLPRegressor-(50,)-relu-0.001-200; -0.9237\n",
      "MLPRegressor-(50,)-relu-0.001-500; -1.1631\n",
      "MLPRegressor-(50,)-relu-0.001-1000; -1.1254\n",
      "MLPRegressor-(50,)-relu-0.01-200; -1.0398\n",
      "MLPRegressor-(50,)-relu-0.01-500; -1.2329\n",
      "MLPRegressor-(50,)-relu-0.01-1000; -1.2656\n",
      "MLPRegressor-(50,)-tanh-0.0001-200; -2.1817\n",
      "MLPRegressor-(50,)-tanh-0.0001-500; -2.4946\n",
      "MLPRegressor-(50,)-tanh-0.0001-1000; -2.7068\n",
      "MLPRegressor-(50,)-tanh-0.001-200; -2.4744\n",
      "MLPRegressor-(50,)-tanh-0.001-500; -2.3440\n",
      "MLPRegressor-(50,)-tanh-0.001-1000; -2.5650\n",
      "MLPRegressor-(50,)-tanh-0.01-200; -2.3407\n",
      "MLPRegressor-(50,)-tanh-0.01-500; -2.4644\n",
      "MLPRegressor-(50,)-tanh-0.01-1000; -2.7327\n",
      "MLPRegressor-(100,)-relu-0.0001-200; -0.8699\n",
      "MLPRegressor-(100,)-relu-0.0001-500; -1.0608\n",
      "MLPRegressor-(100,)-relu-0.0001-1000; -1.0641\n",
      "MLPRegressor-(100,)-relu-0.001-200; -0.8332\n",
      "MLPRegressor-(100,)-relu-0.001-500; -1.0445\n",
      "MLPRegressor-(100,)-relu-0.001-1000; -1.1165\n",
      "MLPRegressor-(100,)-relu-0.01-200; -0.9299\n",
      "MLPRegressor-(100,)-relu-0.01-500; -1.0529\n",
      "MLPRegressor-(100,)-relu-0.01-1000; -1.0455\n",
      "MLPRegressor-(100,)-tanh-0.0001-200; -2.4829\n",
      "MLPRegressor-(100,)-tanh-0.0001-500; -2.7682\n",
      "MLPRegressor-(100,)-tanh-0.0001-1000; -2.6539\n",
      "MLPRegressor-(100,)-tanh-0.001-200; -2.2632\n",
      "MLPRegressor-(100,)-tanh-0.001-500; -2.4089\n",
      "MLPRegressor-(100,)-tanh-0.001-1000; -2.4999\n",
      "MLPRegressor-(100,)-tanh-0.01-200; -2.6003\n",
      "MLPRegressor-(100,)-tanh-0.01-500; -2.3838\n",
      "MLPRegressor-(100,)-tanh-0.01-1000; -2.5284\n",
      "MLPRegressor-(50, 50)-relu-0.0001-200; -1.2467\n",
      "MLPRegressor-(50, 50)-relu-0.0001-500; -1.3124\n",
      "MLPRegressor-(50, 50)-relu-0.0001-1000; -1.3998\n",
      "MLPRegressor-(50, 50)-relu-0.001-200; -0.9409\n",
      "MLPRegressor-(50, 50)-relu-0.001-500; -1.4452\n",
      "MLPRegressor-(50, 50)-relu-0.001-1000; -1.5039\n",
      "MLPRegressor-(50, 50)-relu-0.01-200; -0.9354\n",
      "MLPRegressor-(50, 50)-relu-0.01-500; -1.2348\n",
      "MLPRegressor-(50, 50)-relu-0.01-1000; -1.3469\n",
      "MLPRegressor-(50, 50)-tanh-0.0001-200; -2.0123\n",
      "MLPRegressor-(50, 50)-tanh-0.0001-500; -2.1631\n",
      "MLPRegressor-(50, 50)-tanh-0.0001-1000; -1.9184\n",
      "MLPRegressor-(50, 50)-tanh-0.001-200; -2.3694\n",
      "MLPRegressor-(50, 50)-tanh-0.001-500; -2.4559\n",
      "MLPRegressor-(50, 50)-tanh-0.001-1000; -2.3588\n",
      "MLPRegressor-(50, 50)-tanh-0.01-200; -1.9440\n",
      "MLPRegressor-(50, 50)-tanh-0.01-500; -2.5068\n",
      "MLPRegressor-(50, 50)-tanh-0.01-1000; -2.2174\n",
      "GradientBoostingRegressor-10-0.1; -1.0865\n",
      "GradientBoostingRegressor-10-0.5; -0.8437\n",
      "GradientBoostingRegressor-10-1.0; -1.3656\n",
      "GradientBoostingRegressor-10-2.0; -2.4252\n",
      "GradientBoostingRegressor-100-0.1; -0.6910\n",
      "GradientBoostingRegressor-100-0.5; -0.8934\n",
      "GradientBoostingRegressor-100-1.0; -1.5392\n",
      "GradientBoostingRegressor-100-2.0; -3.5312\n",
      "GradientBoostingRegressor-200-0.1; -0.6798\n",
      "GradientBoostingRegressor-200-0.5; -0.9108\n",
      "GradientBoostingRegressor-200-1.0; -1.5640\n",
      "GradientBoostingRegressor-200-2.0; -3.5324\n",
      "Eval\n",
      "\n",
      "SVR-0.01-2-0.01; -1.6894\n",
      "Eval\n",
      "\n",
      "SVR-0.01-2-0.1; -1.6873\n",
      "Eval\n",
      "\n",
      "SVR-0.01-2-1; -1.6643\n",
      "Eval\n",
      "\n",
      "SVR-0.01-3-0.01; -1.5668\n",
      "Eval\n",
      "\n",
      "SVR-0.01-3-0.1; -1.5722\n",
      "Eval\n",
      "\n",
      "SVR-0.01-3-1; -1.5568\n",
      "Eval\n",
      "\n",
      "SVR-0.01-4-0.01; -1.6896\n",
      "Eval\n",
      "\n",
      "SVR-0.01-4-0.1; -1.6852\n",
      "Eval\n",
      "\n",
      "SVR-0.01-4-1; -1.6482\n",
      "Eval\n",
      "\n",
      "SVR-0.01-5-0.01; -1.8181\n",
      "Eval\n",
      "\n",
      "SVR-0.01-5-0.1; -1.7955\n",
      "Eval\n",
      "\n",
      "SVR-0.01-5-1; -1.9098\n",
      "Eval\n",
      "\n",
      "SVR-0.1-2-0.01; -1.2782\n",
      "Eval\n",
      "\n",
      "SVR-0.1-2-0.1; -1.2765\n",
      "Eval\n",
      "\n",
      "SVR-0.1-2-1; -1.3643\n",
      "Eval\n",
      "\n",
      "SVR-0.1-3-0.01; -1.1375\n",
      "Eval\n",
      "\n",
      "SVR-0.1-3-0.1; -1.1327\n",
      "Eval\n",
      "\n",
      "SVR-0.1-3-1; -1.2067\n",
      "Eval\n",
      "\n",
      "SVR-0.1-4-0.01; -1.9932\n",
      "Eval\n",
      "\n",
      "SVR-0.1-4-0.1; -1.8998\n",
      "Eval\n",
      "\n",
      "SVR-0.1-4-1; -1.4737\n",
      "Eval\n",
      "\n",
      "SVR-0.1-5-0.01; -2.4228\n",
      "Eval\n",
      "\n",
      "SVR-0.1-5-0.1; -2.3479\n",
      "Eval\n",
      "\n",
      "SVR-0.1-5-1; -1.6670\n",
      "Eval\n",
      "\n",
      "SVR-1-2-0.01; -0.9658\n",
      "Eval\n",
      "\n",
      "SVR-1-2-0.1; -0.9604\n",
      "Eval\n",
      "\n",
      "SVR-1-2-1; -1.0247\n",
      "Eval\n",
      "\n",
      "SVR-1-3-0.01; -0.9657\n",
      "Eval\n",
      "\n",
      "SVR-1-3-0.1; -0.9172\n",
      "Eval\n",
      "\n",
      "SVR-1-3-1; -0.9732\n",
      "Eval\n",
      "\n",
      "SVR-1-4-0.01; -4.8475\n",
      "Eval\n",
      "\n",
      "SVR-1-4-0.1; -4.6540\n",
      "Eval\n",
      "\n",
      "SVR-1-4-1; -3.0059\n",
      "Eval\n",
      "\n",
      "SVR-1-5-0.01; -9.5758\n",
      "Eval\n",
      "\n",
      "SVR-1-5-0.1; -9.1490\n",
      "Eval\n",
      "\n",
      "SVR-1-5-1; -5.8500\n",
      "Eval\n",
      "\n",
      "SVR-10-2-0.01; -1.2971\n",
      "Eval\n",
      "\n",
      "SVR-10-2-0.1; -1.3702\n",
      "Eval\n",
      "\n",
      "SVR-10-2-1; -1.1314\n",
      "Eval\n",
      "\n",
      "SVR-10-3-0.01; -1.7136\n",
      "Eval\n",
      "\n",
      "SVR-10-3-0.1; -1.5042\n",
      "Eval\n",
      "\n",
      "SVR-10-3-1; -1.1536\n",
      "Eval\n",
      "\n",
      "SVR-10-4-0.01; -14.1657\n",
      "Eval\n",
      "\n",
      "SVR-10-4-0.1; -13.4468\n",
      "Eval\n",
      "\n",
      "SVR-10-4-1; -6.6358\n",
      "Eval\n",
      "\n",
      "SVR-10-5-0.01; -46.5932\n",
      "Eval\n",
      "\n",
      "SVR-10-5-0.1; -40.8256\n",
      "Eval\n",
      "\n",
      "SVR-10-5-1; -18.8292\n",
      "Eval\n",
      "\n",
      "SVR-100-2-0.01; -3.6477\n",
      "Eval\n",
      "\n",
      "SVR-100-2-0.1; -3.2710\n",
      "Eval\n",
      "\n",
      "SVR-100-2-1; -1.5128\n",
      "Eval\n",
      "\n",
      "SVR-100-3-0.01; -2.1137\n",
      "Eval\n",
      "\n",
      "SVR-100-3-0.1; -1.9775\n",
      "Eval\n",
      "\n",
      "SVR-100-3-1; -1.5009\n",
      "Eval\n",
      "\n",
      "SVR-100-4-0.01; -37.6081\n",
      "Eval\n",
      "\n",
      "SVR-100-4-0.1; -32.2596\n",
      "Eval\n",
      "\n",
      "SVR-100-4-1; -4.5317\n",
      "Eval\n",
      "\n",
      "SVR-100-5-0.01; -183.1532\n",
      "Eval\n",
      "\n",
      "SVR-100-5-0.1; -140.6137\n",
      "Eval\n",
      "\n",
      "SVR-100-5-1; -39.8687\n",
      "Eval\n",
      "\n",
      "SVR-1000-2-0.01; -9.8069\n",
      "Eval\n",
      "\n",
      "SVR-1000-2-0.1; -8.6342\n",
      "Eval\n",
      "\n",
      "SVR-1000-2-1; -1.6242\n",
      "Eval\n",
      "\n",
      "SVR-1000-3-0.01; -3.8006\n",
      "Eval\n",
      "\n",
      "SVR-1000-3-0.1; -3.1072\n",
      "Eval\n",
      "\n",
      "SVR-1000-3-1; -1.7327\n",
      "Eval\n",
      "\n",
      "SVR-1000-4-0.01; -90.3360\n",
      "Eval\n",
      "\n",
      "SVR-1000-4-0.1; -79.0897\n",
      "Eval\n",
      "\n",
      "SVR-1000-4-1; -6.8075\n",
      "Eval\n",
      "\n",
      "SVR-1000-5-0.01; -658.7013\n",
      "Eval\n",
      "\n",
      "SVR-1000-5-0.1; -544.8645\n",
      "Eval\n",
      "\n",
      "SVR-1000-5-1; -42.8716\n"
     ]
    }
   ],
   "source": [
    "run_grid = {\n",
    "        'regression': [False, True],\n",
    "        'pca': [False, True]\n",
    "    }\n",
    "\n",
    "run_param_combinations = list(product(*run_grid.values()))\n",
    "\n",
    "for combination in run_param_combinations:\n",
    "    r, p = combination\n",
    "    run_configured(r, p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
