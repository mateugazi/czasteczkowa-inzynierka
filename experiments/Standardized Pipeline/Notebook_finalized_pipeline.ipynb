{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "#import deepchem as dc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_descriptors = True\n",
    "use_fingerprints = False\n",
    "\n",
    "regression = True\n",
    "threshold = 7\n",
    "\n",
    "scaffold_split = True\n",
    "\n",
    "\n",
    "### All hyperparameters need to be supplimented into a function\n",
    "\n",
    "models_with_parameters = [\n",
    "['rf', {\n",
    "#  \"bootstrap\": True,\n",
    "#  #\"criterion\": \"entropy\",\n",
    "#  #\"criterion\": \"squared_error\",\n",
    "#  \"criterion\": \"entropy\",\n",
    "#  \"min_samples_split\": 32,\n",
    "#  \"n_estimators\": 30\n",
    "}],\n",
    "['lr', {\n",
    "}],\n",
    "['nn', {\n",
    "}],\n",
    "['gb', {\n",
    "}],\n",
    "['sv', {\n",
    "}]\n",
    "]\n",
    "\n",
    "metrics = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data the old way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input standard SMILES column\n",
    "def CalculateMorganFingerprint(mol):\n",
    "    mol = mol.apply(Chem.MolFromSmiles)\n",
    "    mfpgen = AllChem.GetMorganGenerator(radius=2,fpSize=2048)\n",
    "    fingerprint = np.array([mfpgen.GetFingerprintAsNumPy(x) for x in mol])\n",
    "    fingerprint = pd.DataFrame(fingerprint, columns = ['mfp'+str(i) for i in range(fingerprint.shape[1])])\n",
    "    return fingerprint\n",
    "\n",
    "### Input standard SMILES column\n",
    "def CalculateDescriptors(mol):\n",
    "    mol = mol.apply(Chem.MolFromSmiles)\n",
    "    calc = Calculator(descriptors, ignore_3D=False)\n",
    "    X_mordred = calc.pandas(mol, nproc=1)\n",
    "    X_mordred = X_mordred.select_dtypes(['number'])\n",
    "    #normalize\n",
    "    X_mordred = (X_mordred-X_mordred.min())/(X_mordred.max()-X_mordred.min())\n",
    "    #drop columns wth low std\n",
    "    X_mordred = X_mordred.loc[:,X_mordred.std()>0.01]\n",
    "    return X_mordred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_downloaded_CSV(path, regression = False, calculate_pIC50 = False):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    ### Replace with standardizing molecules and then dropping duplicates\n",
    "    #df.drop_duplicates('mol')\n",
    "    #df = df.dropna()\n",
    "    \n",
    "    if 'target' in df.columns:\n",
    "        df['Target'] = df['target']\n",
    "        df.drop('target', axis=1, inplace=True)\n",
    "        \n",
    "    if regression:\n",
    "        if 'IC50' in df.columns:\n",
    "            calculate_pIC50 = True\n",
    "            df['Target'] = df['IC50']\n",
    "            df.drop('IC50', axis=1, inplace=True)\n",
    "        if 'pIC50' in df.columns:\n",
    "            df['Target'] = df['pIC50']\n",
    "            df.drop('pIC50', axis=1, inplace=True)\n",
    "    else:\n",
    "        if 'Class' in df.columns:\n",
    "            df['Target'] = df['Class']\n",
    "            df.drop('Class', axis=1, inplace=True)\n",
    "        \n",
    "    if 'SMILES' in df.columns:\n",
    "        df['mol'] = df['SMILES']\n",
    "        df.drop('SMILES', axis=1, inplace=True)\n",
    "    \n",
    "    if calculate_pIC50:\n",
    "        df['Target'] = [-np.log10(i * 10**(-9)) for i in list(df['Target'])]\n",
    "        if not regression:\n",
    "            df['Target'] = [int(i > 7) for i in list(df['Target'])]\n",
    "\n",
    "    df = df[['mol', 'Target']]\n",
    "\n",
    "    if use_descriptors:\n",
    "        new_df = CalculateDescriptors(df['mol'])\n",
    "    if use_fingerprints:\n",
    "        new_df = CalculateMorganFingerprint(df['mol'])\n",
    "        \n",
    "    new_df['Target'] = df['Target']\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def Split_downloaded_CSV(df):\n",
    "    X = df.drop(['Target'], axis=1)\n",
    "    y = df[['Target']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.111, random_state=42)\n",
    "    return X_train, y_train, X_test, y_test, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_12888\\3922792526.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['Target'] = df['Target']\n"
     ]
    }
   ],
   "source": [
    "### ror-gamma\n",
    "#csv_path = r\"C:\\Users\\admin\\Documents\\GitHub\\czasteczkowa-inzynierka\\experiments\\ROR-gamma\\ROR_data_1.csv\"\n",
    "#df_loaded = Load_downloaded_CSV(csv_path, regression=regression, calculate_pIC50=True)\n",
    "### bace\n",
    "csv_path = r\"C:\\Users\\admin\\Documents\\GitHub\\czasteczkowa-inzynierka\\experiments\\BACE\\bace.csv\"\n",
    "df_loaded = Load_downloaded_CSV(csv_path, regression=regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_valid, y_valid = Split_downloaded_CSV(df_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1209, 1220)\n",
      "(152, 1220)\n",
      "(152, 1220)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(model_name, hyperparams, regression):\n",
    "    if model_name == 'rf':\n",
    "        if \"n_estimators\" not in hyperparams.keys():\n",
    "            hyperparams[\"n_estimators\"] = 100\n",
    "        if \"min_samples_split\" not in hyperparams.keys():\n",
    "            hyperparams[\"min_samples_split\"] = 2\n",
    "        if \"bootstrap\" not in hyperparams.keys():\n",
    "            hyperparams[\"bootstrap\"] = True  \n",
    "\n",
    "        if regression:\n",
    "            if \"criterion\" not in hyperparams.keys():\n",
    "                hyperparams[\"criterion\"] = \"squared_error\"\n",
    "            model = RandomForestRegressor(n_estimators=hyperparams[\"n_estimators\"],\n",
    "                                    min_samples_split=hyperparams[\"min_samples_split\"],\n",
    "                                    criterion=hyperparams[\"criterion\"],\n",
    "                                    bootstrap=hyperparams[\"bootstrap\"])\n",
    "        else:\n",
    "            if \"criterion\" not in hyperparams.keys():\n",
    "                hyperparams[\"criterion\"] = \"gini\"\n",
    "            model = RandomForestClassifier(n_estimators=hyperparams[\"n_estimators\"],\n",
    "                                    min_samples_split=hyperparams[\"min_samples_split\"], \n",
    "                                    criterion=hyperparams[\"criterion\"],\n",
    "                                    bootstrap=hyperparams[\"bootstrap\"])\n",
    "            \n",
    "    if model_name == 'lr':\n",
    "        if regression:\n",
    "            model = LinearRegression()\n",
    "        else:\n",
    "            if \"C\" not in hyperparams.keys():\n",
    "                hyperparams[\"C\"] = 1\n",
    "            if \"penalty\" not in hyperparams.keys():\n",
    "                hyperparams[\"penalty\"] = \"l2\"\n",
    "            if \"solver\" not in hyperparams.keys():\n",
    "                hyperparams[\"solver\"] = \"liblinear\"\n",
    "            model = LogisticRegression(C=hyperparams[\"C\"], penalty=hyperparams[\"penalty\"], solver=hyperparams[\"solver\"])\n",
    "\n",
    "    if model_name == 'nn':\n",
    "        if \"hidden_layer_sizes\" not in hyperparams.keys():\n",
    "            hyperparams[\"hidden_layer_sizes\"] = (100,)\n",
    "        if \"activation\" not in hyperparams.keys():\n",
    "            hyperparams[\"activation\"] = \"relu\"\n",
    "        if \"alpha\" not in hyperparams.keys():\n",
    "            hyperparams[\"alpha\"] = 0.0001  \n",
    "        if \"max_iter\" not in hyperparams.keys():\n",
    "            hyperparams[\"max_iter\"] = 500#200\n",
    "        if regression:\n",
    "            model = MLPRegressor(hidden_layer_sizes=hyperparams[\"hidden_layer_sizes\"], activation=hyperparams[\"activation\"], \n",
    "                                  alpha=hyperparams[\"alpha\"], max_iter=hyperparams[\"max_iter\"])\n",
    "        else:\n",
    "            model = MLPClassifier(hidden_layer_sizes=hyperparams[\"hidden_layer_sizes\"], activation=hyperparams[\"activation\"], \n",
    "                                  alpha=hyperparams[\"alpha\"], max_iter=hyperparams[\"max_iter\"])\n",
    "        \n",
    "    if model_name == 'gb':\n",
    "        if \"n_estimators\" not in hyperparams.keys():\n",
    "            hyperparams[\"n_estimators\"] = 100\n",
    "        if \"learning_rate\" not in hyperparams.keys():\n",
    "            hyperparams[\"learning_rate\"] = 0.1\n",
    "        if regression:\n",
    "            model = GradientBoostingRegressor(n_estimators=hyperparams[\"n_estimators\"], learning_rate=hyperparams[\"learning_rate\"])\n",
    "        else:\n",
    "            model = GradientBoostingClassifier(n_estimators=hyperparams[\"n_estimators\"], learning_rate=hyperparams[\"learning_rate\"])\n",
    "\n",
    "    if model_name == 'sv':\n",
    "        if \"C\" not in hyperparams.keys():\n",
    "            hyperparams[\"C\"] = 1\n",
    "        if \"degree\" not in hyperparams.keys():\n",
    "            hyperparams[\"degree\"] = 3\n",
    "        if \"kernel\" not in hyperparams.keys():\n",
    "            hyperparams[\"kernel\"] = \"rbf\"\n",
    "        if regression:\n",
    "            if \"epsilon\" not in hyperparams.keys():\n",
    "                hyperparams[\"epsilon\"] = 0.1\n",
    "            model = SVR(C=hyperparams[\"C\"], degree=hyperparams[\"degree\"], kernel=hyperparams[\"kernel\"], epsilon=hyperparams[\"epsilon\"])\n",
    "        else:\n",
    "            model = SVC(C=hyperparams[\"C\"], degree=hyperparams[\"degree\"], kernel=hyperparams[\"kernel\"])\n",
    "            \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, X_train, y_train, X_test, y_test, X_valid, y_valid, regression, metrics=[], iterations=1):\n",
    "    for i in range(iterations):\n",
    "        model.fit(X_train, np.reshape(y_train, (-1, )))\n",
    "        \n",
    "        y_test_predicted = model.predict(X_test)\n",
    "        y_valid_predicted = model.predict(X_valid)\n",
    "\n",
    "        #print(\"Standard train-test results:\")\n",
    "\n",
    "        results_test = {}\n",
    "        results_valid = {}\n",
    "\n",
    "        if regression:\n",
    "            if 'rmse' in metrics or len(metrics) == 0:\n",
    "                metric_test = mean_squared_error(y_test, y_test_predicted, squared=False)\n",
    "                metric_valid = mean_squared_error(y_valid, y_valid_predicted, squared=False)\n",
    "                results_test[\"rmse\"] = metric_test\n",
    "                results_valid[\"rmse\"] = metric_valid\n",
    "            if 'mse' in metrics or len(metrics) == 0:\n",
    "                metric_test = mean_squared_error(y_test, y_test_predicted)\n",
    "                metric_valid = mean_squared_error(y_valid, y_valid_predicted)\n",
    "                results_test[\"mse\"] = metric_test\n",
    "                results_valid[\"mse\"] = metric_valid\n",
    "            if 'mae' in metrics or len(metrics) == 0:\n",
    "                metric_test = mean_absolute_error(y_test, y_test_predicted)\n",
    "                metric_valid = mean_absolute_error(y_valid, y_valid_predicted)\n",
    "                results_test[\"mae\"] = metric_test\n",
    "                results_valid[\"mae\"] = metric_valid\n",
    "            if 'r2' in metrics or len(metrics) == 0:\n",
    "                metric_test = r2_score(y_test, y_test_predicted)\n",
    "                metric_valid = r2_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"r2\"] = metric_test\n",
    "                results_valid[\"r2\"] = metric_valid\n",
    "            \n",
    "        else:\n",
    "            if 'roc_auc' in metrics or len(metrics) == 0:\n",
    "                metric_test = roc_auc_score(y_test, y_test_predicted)\n",
    "                metric_valid = roc_auc_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"roc_auc\"] = metric_test\n",
    "                results_valid[\"roc_auc\"] = metric_valid\n",
    "            if 'accuracy' in metrics or len(metrics) == 0:\n",
    "                metric_test = accuracy_score(y_test, y_test_predicted)\n",
    "                metric_valid = accuracy_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"accuracy\"] = metric_test\n",
    "                results_valid[\"accuracy\"] = metric_valid\n",
    "            if 'precision' in metrics or len(metrics) == 0:\n",
    "                metric_test = precision_score(y_test, y_test_predicted)\n",
    "                metric_valid = precision_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"precision\"] = metric_test\n",
    "                results_valid[\"precision\"] = metric_valid\n",
    "            if 'recall' in metrics or len(metrics) == 0:\n",
    "                metric_test = recall_score(y_test, y_test_predicted)\n",
    "                metric_valid = recall_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"recall\"] = metric_test\n",
    "                results_valid[\"recall\"] = metric_valid\n",
    "            if 'f1' in metrics or len(metrics) == 0:\n",
    "                metric_test = f1_score(y_test, y_test_predicted)\n",
    "                metric_valid = f1_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"f1\"] = metric_test\n",
    "                results_valid[\"f1\"] = metric_valid\n",
    "\n",
    "    return results_test, results_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "{'rmse': 0.7245011008975704, 'mse': 0.5249018452017914, 'mae': 0.5580280639451204, 'r2': 0.7120181662438041}\n",
      "{'rmse': 0.6943787540083267, 'mse': 0.4821618540181563, 'mae': 0.5259046646528743, 'r2': 0.7148523137660241}\n",
      "lr\n",
      "{'rmse': 3.5797579415337184, 'mse': 12.814666919973726, 'mae': 1.8354871385690792, 'r2': -6.030631178616216}\n",
      "{'rmse': 19.952064602563127, 'mse': 398.0848819048525, 'mae': 4.1860628997481495, 'r2': -234.42505914542923}\n",
      "nn\n",
      "{'rmse': 0.9488780459383465, 'mse': 0.9003695460637747, 'mae': 0.7660887487655016, 'r2': 0.5060217918761574}\n",
      "{'rmse': 0.8427382666162169, 'mse': 0.7102077860193059, 'mae': 0.7149876502464926, 'r2': 0.5799872900747268}\n",
      "gb\n",
      "{'rmse': 0.6993894585993036, 'mse': 0.48914561479982693, 'mae': 0.5433892482426249, 'r2': 0.731635443061355}\n",
      "{'rmse': 0.7003646091970713, 'mse': 0.4905105858157665, 'mae': 0.53146507710448, 'r2': 0.7099149228562344}\n",
      "sv\n",
      "{'rmse': 0.7673992774203482, 'mse': 0.5889016509852725, 'mae': 0.5861397563961007, 'r2': 0.676905351156477}\n",
      "{'rmse': 0.6510818713272698, 'mse': 0.42390760317101955, 'mae': 0.5025744151202853, 'r2': 0.7493035352882665}\n"
     ]
    }
   ],
   "source": [
    "for model_name, hyperparams in models_with_parameters:\n",
    "    print(model_name)\n",
    "\n",
    "    model = model_builder(model_name, hyperparams, regression)\n",
    "    results_test, results_valid = train_and_test(model, X_train, y_train, X_test, y_test, X_valid, y_valid, regression=regression, metrics=metrics)\n",
    "    print(results_test)\n",
    "    print(results_valid)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_dict_reg = {\"rf\": \"RandomForestRegressor\", \"lr\": \"LinearRegression\", \"nn\": \"MLPRegressor\", \"gb\": \"GradientBoostingRegressor\", \"sv\": \"SVR\"}\n",
    "model_name_dict_class = {\"rf\": \"RandomForestClassifier\", \"lr\": \"LogisticRegression\", \"nn\": \"MLPClassifier\", \"gb\": \"GradientBoostingClassifier\", \"sv\": \"SVC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.7222102843383881, 'mse': 0.5215876948041354, 'mae': 0.5579373519986839, 'r2': 0.7138364397316671}\n",
      "{'rmse': 0.7043392967840308, 'mse': 0.4960938449942231, 'mae': 0.531224259782378, 'r2': 0.7066130161974766}\n",
      "{'rmse': 3.5797579415337184, 'mse': 12.814666919973726, 'mae': 1.8354871385690792, 'r2': -6.030631178616216}\n",
      "{'rmse': 19.952064602563127, 'mse': 398.0848819048525, 'mae': 4.1860628997481495, 'r2': -234.42505914542923}\n",
      "{'rmse': 0.8080527634823731, 'mse': 0.6529492685714999, 'mae': 0.6204444133739621, 'r2': 0.6417663046303468}\n",
      "{'rmse': 0.6903936710127397, 'mse': 0.4766434209744472, 'mae': 0.5278811525425215, 'r2': 0.7181158826297516}\n",
      "{'rmse': 0.6976516326761565, 'mse': 0.48671780057570685, 'mae': 0.5429715945500043, 'r2': 0.7329674376021871}\n",
      "{'rmse': 0.7008886948052593, 'mse': 0.4912449625058199, 'mae': 0.527794848248927, 'r2': 0.7094806167985324}\n",
      "{'rmse': 0.7673992774203482, 'mse': 0.5889016509852725, 'mae': 0.5861397563961007, 'r2': 0.676905351156477}\n",
      "{'rmse': 0.6510818713272698, 'mse': 0.42390760317101955, 'mae': 0.5025744151202853, 'r2': 0.7493035352882665}\n"
     ]
    }
   ],
   "source": [
    "### Row by row\n",
    "data = {\"model\": [], \"set\": []}\n",
    "if regression:\n",
    "    for metric in [\"rmse\", \"mse\", \"mae\", \"r2\"]:\n",
    "        data[metric] = []\n",
    "else:\n",
    "    for metric in [\"roc_auc\", \"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "        data[metric] = []\n",
    "\n",
    "results_df = pd.DataFrame(data)\n",
    "for model_name, hyperparams in models_with_parameters:\n",
    "\n",
    "    model = model_builder(model_name, hyperparams, regression)\n",
    "    results_test, results_valid = train_and_test(model, X_train, y_train, X_test, y_test, X_valid, y_valid, regression=regression, metrics=metrics)\n",
    "    print(results_test)\n",
    "    print(results_valid)\n",
    "    if regression:\n",
    "        results_test[\"model\"] = model_name_dict_reg[model_name]\n",
    "    else:\n",
    "        results_test[\"model\"] = model_name_dict_class[model_name]\n",
    "    results_test[\"set\"] = \"test\"\n",
    "    results_df.loc[len(results_df)] = results_test\n",
    "    if regression:\n",
    "        results_valid[\"model\"] = model_name_dict_reg[model_name]\n",
    "    else:\n",
    "        results_valid[\"model\"] = model_name_dict_class[model_name]\n",
    "    results_valid[\"set\"] = \"valid\"\n",
    "    results_df.loc[len(results_df)] = results_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>set</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>test</td>\n",
       "      <td>0.722210</td>\n",
       "      <td>0.521588</td>\n",
       "      <td>0.557937</td>\n",
       "      <td>0.713836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.704339</td>\n",
       "      <td>0.496094</td>\n",
       "      <td>0.531224</td>\n",
       "      <td>0.706613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>test</td>\n",
       "      <td>3.579758</td>\n",
       "      <td>12.814667</td>\n",
       "      <td>1.835487</td>\n",
       "      <td>-6.030631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>valid</td>\n",
       "      <td>19.952065</td>\n",
       "      <td>398.084882</td>\n",
       "      <td>4.186063</td>\n",
       "      <td>-234.425059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>test</td>\n",
       "      <td>0.808053</td>\n",
       "      <td>0.652949</td>\n",
       "      <td>0.620444</td>\n",
       "      <td>0.641766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.690394</td>\n",
       "      <td>0.476643</td>\n",
       "      <td>0.527881</td>\n",
       "      <td>0.718116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>test</td>\n",
       "      <td>0.697652</td>\n",
       "      <td>0.486718</td>\n",
       "      <td>0.542972</td>\n",
       "      <td>0.732967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.700889</td>\n",
       "      <td>0.491245</td>\n",
       "      <td>0.527795</td>\n",
       "      <td>0.709481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR</td>\n",
       "      <td>test</td>\n",
       "      <td>0.767399</td>\n",
       "      <td>0.588902</td>\n",
       "      <td>0.586140</td>\n",
       "      <td>0.676905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.651082</td>\n",
       "      <td>0.423908</td>\n",
       "      <td>0.502574</td>\n",
       "      <td>0.749304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model    set       rmse         mse       mae  \\\n",
       "0      RandomForestRegressor   test   0.722210    0.521588  0.557937   \n",
       "1      RandomForestRegressor  valid   0.704339    0.496094  0.531224   \n",
       "2           LinearRegression   test   3.579758   12.814667  1.835487   \n",
       "3           LinearRegression  valid  19.952065  398.084882  4.186063   \n",
       "4               MLPRegressor   test   0.808053    0.652949  0.620444   \n",
       "5               MLPRegressor  valid   0.690394    0.476643  0.527881   \n",
       "6  GradientBoostingRegressor   test   0.697652    0.486718  0.542972   \n",
       "7  GradientBoostingRegressor  valid   0.700889    0.491245  0.527795   \n",
       "8                        SVR   test   0.767399    0.588902  0.586140   \n",
       "9                        SVR  valid   0.651082    0.423908  0.502574   \n",
       "\n",
       "           r2  \n",
       "0    0.713836  \n",
       "1    0.706613  \n",
       "2   -6.030631  \n",
       "3 -234.425059  \n",
       "4    0.641766  \n",
       "5    0.718116  \n",
       "6    0.732967  \n",
       "7    0.709481  \n",
       "8    0.676905  \n",
       "9    0.749304  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"results.csv\"\n",
    "results_df.to_csv(csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
