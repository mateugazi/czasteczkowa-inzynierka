{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import deepchem as dc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_descriptors = True\n",
    "use_fingerprints = False\n",
    "\n",
    "regression = True\n",
    "\n",
    "models_with_parameters = [\n",
    "['rf', {\n",
    "#  \"bootstrap\": True,\n",
    "#  #\"criterion\": \"entropy\",\n",
    "#  #\"criterion\": \"squared_error\",\n",
    "#  \"criterion\": \"entropy\",\n",
    "#  \"min_samples_split\": 32,\n",
    "#  \"n_estimators\": 30\n",
    "}],\n",
    "['lr', {\n",
    "}],\n",
    "['nn', {\n",
    "}],\n",
    "['gb', {\n",
    "}],\n",
    "['sv', {\n",
    "}]\n",
    "]\n",
    "\n",
    "metrics = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data the old way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input standard SMILES column\n",
    "def CalculateMorganFingerprint(mol):\n",
    "    mol = mol.apply(Chem.MolFromSmiles)\n",
    "    mfpgen = AllChem.GetMorganGenerator(radius=2,fpSize=2048)\n",
    "    fingerprint = np.array([mfpgen.GetFingerprintAsNumPy(x) for x in mol])\n",
    "    fingerprint = pd.DataFrame(fingerprint, columns = ['mfp'+str(i) for i in range(fingerprint.shape[1])])\n",
    "    return fingerprint\n",
    "\n",
    "### Input standard SMILES column\n",
    "def CalculateDescriptors(mol):\n",
    "    mol = mol.apply(Chem.MolFromSmiles)\n",
    "    calc = Calculator(descriptors, ignore_3D=False)\n",
    "    X_mordred = calc.pandas(mol, nproc=1)\n",
    "    X_mordred = X_mordred.select_dtypes(['number'])\n",
    "    #normalize\n",
    "    X_mordred = (X_mordred-X_mordred.min())/(X_mordred.max()-X_mordred.min())\n",
    "    #drop columns wth low std\n",
    "    X_mordred = X_mordred.loc[:,X_mordred.std()>0.01]\n",
    "    return X_mordred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_downloaded_CSV_BACE(path, regression = False):\n",
    "    df = pd.read_csv(path)\n",
    "    df.drop_duplicates('mol')\n",
    "    df = df.dropna()\n",
    "    #df.drop(['CID', 'canvasUID'], axis=1, inplace=True)\n",
    "\n",
    "    if regression:\n",
    "        df['Target'] = df['pIC50']\n",
    "        df.drop('Class', axis=1, inplace=True)\n",
    "        df.drop('pIC50', axis=1, inplace=True)\n",
    "    else:\n",
    "        df['Target'] = df['Class']\n",
    "        df.drop('Class', axis=1, inplace=True)\n",
    "        df.drop('pIC50', axis=1, inplace=True)\n",
    "\n",
    "    df = df[['mol', 'Target', 'Model']]\n",
    "\n",
    "    if use_descriptors:\n",
    "        new_df = CalculateDescriptors(df['mol'])\n",
    "    if use_fingerprints:\n",
    "        new_df = CalculateMorganFingerprint(df['mol'])\n",
    "        \n",
    "    new_df['Target'] = df['Target']\n",
    "    new_df['Model'] = df['Model']\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def Split_downloaded_CSV_BACE(df, scaffold=True):\n",
    "    if not scaffold:\n",
    "        X = df.drop(['Target', 'Model'], axis=1)\n",
    "        y = df[['Target']]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.111, random_state=42)\n",
    "        return X_train, y_train, X_test, y_test, X_valid, y_valid\n",
    "\n",
    "    X = df.drop(['Target'], axis=1)\n",
    "    y = df[['Target', 'Model']]\n",
    "\n",
    "    X_train = X[X['Model'] == 'Train']\n",
    "    y_train = y[y['Model'] == 'Train']\n",
    "    X_test = X[X['Model'] == 'Test']\n",
    "    y_test = y[y['Model'] == 'Test']\n",
    "    X_valid = X[X['Model'] == 'Valid']\n",
    "    y_valid = y[y['Model'] == 'Valid']\n",
    "    \n",
    "    X_train = X_train.drop('Model', axis=1)\n",
    "    y_train = y_train.drop('Model', axis=1)\n",
    "    X_test = X_test.drop('Model', axis=1)\n",
    "    y_test = y_test.drop('Model', axis=1)\n",
    "    X_valid = X_valid.drop('Model', axis=1)\n",
    "    y_valid = y_valid.drop('Model', axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wojci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "100%|██████████| 1513/1513 [04:28<00:00,  5.63it/s]\n",
      "C:\\Users\\wojci\\AppData\\Local\\Temp\\ipykernel_19972\\898515923.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['Target'] = df['Target']\n",
      "C:\\Users\\wojci\\AppData\\Local\\Temp\\ipykernel_19972\\898515923.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['Model'] = df['Model']\n"
     ]
    }
   ],
   "source": [
    "df_loaded = Load_downloaded_CSV_BACE(r\"C:\\Users\\wojci\\Documents\\GitHub\\czasteczkowa-inzynierka\\experiments\\BACE\\bace.csv\", regression=regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold_split = True\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_valid, y_valid = Split_downloaded_CSV_BACE(df_loaded, scaffold=scaffold_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 1222)\n",
      "(1265, 1222)\n",
      "(45, 1222)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(model_name, hyperparams, regression):\n",
    "    if model_name == 'rf':\n",
    "        if \"n_estimators\" not in hyperparams.keys():\n",
    "            hyperparams[\"n_estimators\"] = 100\n",
    "        if \"min_samples_split\" not in hyperparams.keys():\n",
    "            hyperparams[\"min_samples_split\"] = 2\n",
    "        if \"bootstrap\" not in hyperparams.keys():\n",
    "            hyperparams[\"bootstrap\"] = True  \n",
    "\n",
    "        if regression:\n",
    "            if \"criterion\" not in hyperparams.keys():\n",
    "                hyperparams[\"criterion\"] = \"squared_error\"\n",
    "            model = RandomForestRegressor(n_estimators=hyperparams[\"n_estimators\"],\n",
    "                                    min_samples_split=hyperparams[\"min_samples_split\"],\n",
    "                                    criterion=hyperparams[\"criterion\"],\n",
    "                                    bootstrap=hyperparams[\"bootstrap\"])\n",
    "        else:\n",
    "            if \"criterion\" not in hyperparams.keys():\n",
    "                hyperparams[\"criterion\"] = \"gini\"\n",
    "            model = RandomForestClassifier(n_estimators=hyperparams[\"n_estimators\"],\n",
    "                                    min_samples_split=hyperparams[\"min_samples_split\"], \n",
    "                                    criterion=hyperparams[\"criterion\"],\n",
    "                                    bootstrap=hyperparams[\"bootstrap\"])\n",
    "            \n",
    "    if model_name == 'lr':\n",
    "        if regression:\n",
    "            model = LinearRegression()\n",
    "        else:\n",
    "            if \"C\" not in hyperparams.keys():\n",
    "                hyperparams[\"C\"] = 1\n",
    "            if \"penalty\" not in hyperparams.keys():\n",
    "                hyperparams[\"penalty\"] = \"l2\"\n",
    "            if \"solver\" not in hyperparams.keys():\n",
    "                hyperparams[\"solver\"] = \"liblinear\"\n",
    "            model = LogisticRegression(C=hyperparams[\"C\"], penalty=hyperparams[\"penalty\"], solver=hyperparams[\"solver\"])\n",
    "\n",
    "    if model_name == 'nn':\n",
    "        if \"hidden_layer_sizes\" not in hyperparams.keys():\n",
    "            hyperparams[\"hidden_layer_sizes\"] = (100,)\n",
    "        if \"activation\" not in hyperparams.keys():\n",
    "            hyperparams[\"activation\"] = \"relu\"\n",
    "        if \"alpha\" not in hyperparams.keys():\n",
    "            hyperparams[\"alpha\"] = 0.0001  \n",
    "        if \"max_iter\" not in hyperparams.keys():\n",
    "            hyperparams[\"max_iter\"] = 500#200\n",
    "        if regression:\n",
    "            model = MLPRegressor(hidden_layer_sizes=hyperparams[\"hidden_layer_sizes\"], activation=hyperparams[\"activation\"], \n",
    "                                  alpha=hyperparams[\"alpha\"], max_iter=hyperparams[\"max_iter\"])\n",
    "        else:\n",
    "            model = MLPClassifier(hidden_layer_sizes=hyperparams[\"hidden_layer_sizes\"], activation=hyperparams[\"activation\"], \n",
    "                                  alpha=hyperparams[\"alpha\"], max_iter=hyperparams[\"max_iter\"])\n",
    "        \n",
    "    if model_name == 'gb':\n",
    "        if \"n_estimators\" not in hyperparams.keys():\n",
    "            hyperparams[\"n_estimators\"] = 100\n",
    "        if \"learning_rate\" not in hyperparams.keys():\n",
    "            hyperparams[\"learning_rate\"] = 0.1\n",
    "        if regression:\n",
    "            model = GradientBoostingRegressor(n_estimators=hyperparams[\"n_estimators\"], learning_rate=hyperparams[\"learning_rate\"])\n",
    "        else:\n",
    "            model = GradientBoostingClassifier(n_estimators=hyperparams[\"n_estimators\"], learning_rate=hyperparams[\"learning_rate\"])\n",
    "\n",
    "    if model_name == 'sv':\n",
    "        if \"C\" not in hyperparams.keys():\n",
    "            hyperparams[\"C\"] = 1\n",
    "        if \"degree\" not in hyperparams.keys():\n",
    "            hyperparams[\"degree\"] = 3\n",
    "        if \"kernel\" not in hyperparams.keys():\n",
    "            hyperparams[\"kernel\"] = \"rbf\"\n",
    "        if regression:\n",
    "            if \"epsilon\" not in hyperparams.keys():\n",
    "                hyperparams[\"epsilon\"] = 0.1\n",
    "            model = SVR(C=hyperparams[\"C\"], degree=hyperparams[\"degree\"], kernel=hyperparams[\"kernel\"], epsilon=hyperparams[\"epsilon\"])\n",
    "        else:\n",
    "            model = SVC(C=hyperparams[\"C\"], degree=hyperparams[\"degree\"], kernel=hyperparams[\"kernel\"])\n",
    "            \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, X_train, y_train, X_test, y_test, X_valid, y_valid, regression, metrics=[], iterations=1):\n",
    "    for i in range(iterations):\n",
    "        model.fit(X_train, np.reshape(y_train, (-1, )))\n",
    "        \n",
    "        y_test_predicted = model.predict(X_test)\n",
    "        y_valid_predicted = model.predict(X_valid)\n",
    "\n",
    "        #print(\"Standard train-test results:\")\n",
    "\n",
    "        results_test = {}\n",
    "        results_valid = {}\n",
    "\n",
    "        if regression:\n",
    "            if 'rmse' in metrics or len(metrics) == 0:\n",
    "                metric_test = mean_squared_error(y_test, y_test_predicted, squared=False)\n",
    "                metric_valid = mean_squared_error(y_valid, y_valid_predicted, squared=False)\n",
    "                results_test[\"rmse\"] = metric_test\n",
    "                results_valid[\"rmse\"] = metric_valid\n",
    "            if 'mse' in metrics or len(metrics) == 0:\n",
    "                metric_test = mean_squared_error(y_test, y_test_predicted)\n",
    "                metric_valid = mean_squared_error(y_valid, y_valid_predicted)\n",
    "                results_test[\"mse\"] = metric_test\n",
    "                results_valid[\"mse\"] = metric_valid\n",
    "            if 'mae' in metrics or len(metrics) == 0:\n",
    "                metric_test = mean_absolute_error(y_test, y_test_predicted)\n",
    "                metric_valid = mean_absolute_error(y_valid, y_valid_predicted)\n",
    "                results_test[\"mae\"] = metric_test\n",
    "                results_valid[\"mae\"] = metric_valid\n",
    "            if 'r2' in metrics or len(metrics) == 0:\n",
    "                metric_test = r2_score(y_test, y_test_predicted)\n",
    "                metric_valid = r2_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"r2\"] = metric_test\n",
    "                results_valid[\"r2\"] = metric_valid\n",
    "            \n",
    "        else:\n",
    "            if 'roc_auc' in metrics or len(metrics) == 0:\n",
    "                metric_test = roc_auc_score(y_test, y_test_predicted)\n",
    "                metric_valid = roc_auc_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"roc_auc\"] = metric_test\n",
    "                results_valid[\"roc_auc\"] = metric_valid\n",
    "            if 'accuracy' in metrics or len(metrics) == 0:\n",
    "                metric_test = accuracy_score(y_test, y_test_predicted)\n",
    "                metric_valid = accuracy_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"accuracy\"] = metric_test\n",
    "                results_valid[\"accuracy\"] = metric_valid\n",
    "            if 'precision' in metrics or len(metrics) == 0:\n",
    "                metric_test = precision_score(y_test, y_test_predicted)\n",
    "                metric_valid = precision_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"precision\"] = metric_test\n",
    "                results_valid[\"precision\"] = metric_valid\n",
    "            if 'recall' in metrics or len(metrics) == 0:\n",
    "                metric_test = recall_score(y_test, y_test_predicted)\n",
    "                metric_valid = recall_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"recall\"] = metric_test\n",
    "                results_valid[\"recall\"] = metric_valid\n",
    "            if 'f1' in metrics or len(metrics) == 0:\n",
    "                metric_test = f1_score(y_test, y_test_predicted)\n",
    "                metric_valid = f1_score(y_valid, y_valid_predicted)\n",
    "                results_test[\"f1\"] = metric_test\n",
    "                results_valid[\"f1\"] = metric_valid\n",
    "\n",
    "    return results_test, results_valid\n",
    "                \n",
    "\n",
    "def benchmark_train_and_test(model, X_train, y_train, X_test, y_test, X_valid, y_valid, regression, metrics=[], iterations=1):\n",
    "    model = dc.models.SklearnModel(model) ### for benchmark \n",
    "    for i in range(iterations):\n",
    "\n",
    "        if regression:\n",
    "            task = \"pIC50\"\n",
    "        else:\n",
    "            task = \"Class\"\n",
    "\n",
    "        train_set = dc.data.DiskDataset.from_numpy(X=X_train.to_numpy(), y=np.reshape(y_train.to_numpy(), (-1, )), w=np.ones_like(y_train), ids=np.array([i for i in range(y_train.shape[0])]), tasks=[task])\n",
    "        test_set = dc.data.DiskDataset.from_numpy(X=X_test.to_numpy(), y=np.reshape(y_test.to_numpy(), (-1, )), w=np.ones_like(y_test), ids=np.array([i for i in range(y_test.shape[0])]), tasks=[task])\n",
    "        valid_set = dc.data.DiskDataset.from_numpy(X=X_valid.to_numpy(), y=np.reshape(y_valid.to_numpy(), (-1, )), w=np.ones_like(y_valid), ids=np.array([i for i in range(y_valid.shape[0])]), tasks=[task])\n",
    "\n",
    "        model.fit(train_set)\n",
    "        \n",
    "        used_metrics = []\n",
    "        if regression:\n",
    "            if 'rmse' in metrics or len(metrics) == 0:\n",
    "                used_metrics.append(dc.metrics.Metric(dc.metrics.rms_score, np.mean))\n",
    "            if 'mse' in metrics or len(metrics) == 0:\n",
    "                used_metrics.append(dc.metrics.Metric(dc.metrics.mean_squared_error, np.mean))\n",
    "            if 'mae' in metrics or len(metrics) == 0:\n",
    "                used_metrics.append(dc.metrics.Metric(dc.metrics.mean_absolute_error, np.mean))\n",
    "            if 'r2' in metrics or len(metrics) == 0:\n",
    "                used_metrics.append(dc.metrics.Metric(dc.metrics.r2_score, np.mean))\n",
    "\n",
    "        else:\n",
    "            if 'roc_auc' in metrics or len(metrics) == 0:\n",
    "                used_metrics.append(dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean))\n",
    "            if 'accuracy' in metrics or len(metrics) == 0:\n",
    "                used_metrics.append(dc.metrics.Metric(dc.metrics.accuracy_score, np.mean))\n",
    "            #f 'precision' in metrics or len(metrics) == 0:\n",
    "            #   used_metrics.append(dc.metrics.Metric(dc.metrics.precision_score))\n",
    "            #f 'recall' in metrics or len(metrics) == 0:\n",
    "            #   used_metrics.append(dc.metrics.Metric(dc.metrics.recall_score))\n",
    "            if 'f1' in metrics or len(metrics) == 0:\n",
    "                used_metrics.append(dc.metrics.Metric(dc.metrics.f1_score, np.mean))\n",
    "\n",
    "\n",
    "        #print(\"Train-test results using benchmark methodology:\")\n",
    "        #print(list(test_set.y))\n",
    "        \n",
    "        test_metric = model.evaluate(test_set, used_metrics, n_classes=2) #, transformers)\n",
    "        valid_metric = model.evaluate(valid_set, used_metrics, n_classes=2) #, transformers)\n",
    "        \n",
    "        #print(\"Test:\")\n",
    "        #print(test_metric)\n",
    "        #print(\"Valid:\")\n",
    "        #print(valid_metric)\n",
    "\n",
    "        return test_metric, valid_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "{'mean-rms_score': 1.106354849049714, 'mean-mean_squared_error': 1.2240210520158155, 'mean-mean_absolute_error': 0.8063695626360322, 'mean-r2_score': 0.24745795181699715}\n",
      "{'mean-rms_score': 1.3763053549607098, 'mean-mean_squared_error': 1.8942164300935254, 'mean-mean_absolute_error': 1.0903721305059269, 'mean-r2_score': 0.5172123524866401}\n",
      "{'rmse': 1.107181199888776, 'mse': 1.2258502093871495, 'mae': 0.8122684907638641, 'r2': 0.2463333650850893}\n",
      "{'rmse': 1.433511725198337, 'mse': 2.0549558662811123, 'mae': 1.1418429483217998, 'r2': 0.47624395361376304}\n",
      "lr\n",
      "{'mean-rms_score': 127047180.50147216, 'mean-mean_squared_error': 1.6140986073373646e+16, 'mean-mean_absolute_error': 92728804.97208469, 'mean-r2_score': -9923661606428792.0}\n",
      "{'mean-rms_score': 173583140.66615406, 'mean-mean_squared_error': 3.0131106723525824e+16, 'mean-mean_absolute_error': 128864218.27741078, 'mean-r2_score': -7679653655684303.0}\n",
      "{'rmse': 127047180.50147212, 'mse': 1.6140986073373638e+16, 'mae': 92728804.97208469, 'r2': -9923661606428788.0}\n",
      "{'rmse': 173583140.66615397, 'mse': 3.0131106723525796e+16, 'mae': 128864218.27741067, 'r2': -7679653655684295.0}\n",
      "nn\n",
      "{'rmse': 1.0714365778874775, 'mse': 1.1479763404352286, 'mae': 0.8320003328878189, 'r2': 0.29421110439725284}\n",
      "{'rmse': 1.259441705255746, 'mse': 1.5861934089375016, 'mae': 1.0477741304807566, 'r2': 0.5957195955879642}\n",
      "gb\n",
      "{'mean-rms_score': 1.0916076787169224, 'mean-mean_squared_error': 1.191607324233748, 'mean-mean_absolute_error': 0.7926372086120481, 'mean-r2_score': 0.2673862798912501}\n",
      "{'mean-rms_score': 1.4710128673748124, 'mean-mean_squared_error': 2.1638788559822673, 'mean-mean_absolute_error': 1.175289614117713, 'mean-r2_score': 0.4484822506095577}\n",
      "{'rmse': 1.0911224548555674, 'mse': 1.1905482114900396, 'mae': 0.7922918909020671, 'r2': 0.2680374344380565}\n",
      "{'rmse': 1.4660392344321231, 'mse': 2.1492710368943255, 'mae': 1.1699902960553592, 'r2': 0.4522054125992465}\n",
      "sv\n",
      "{'mean-rms_score': 1.130792414461001, 'mean-mean_squared_error': 1.2786914846025406, 'mean-mean_absolute_error': 0.8244696695108115, 'mean-r2_score': 0.21384594878313645}\n",
      "{'mean-rms_score': 1.4513757785636463, 'mean-mean_squared_error': 2.106491650601231, 'mean-mean_absolute_error': 1.0910949760861206, 'mean-r2_score': 0.46310879140136607}\n",
      "{'rmse': 1.130792414461001, 'mse': 1.2786914846025406, 'mae': 0.8244696695108115, 'r2': 0.21384594878313645}\n",
      "{'rmse': 1.4513757785636463, 'mse': 2.106491650601231, 'mae': 1.0910949760861206, 'r2': 0.46310879140136607}\n"
     ]
    }
   ],
   "source": [
    "for model_name, hyperparams in models_with_parameters:\n",
    "    print(model_name)\n",
    "    model = model_builder(model_name, hyperparams, regression)\n",
    "    if model_name != \"nn\":\n",
    "        results_test, results_valid = benchmark_train_and_test(model, X_train, y_train, X_test, y_test, X_valid, y_valid, regression=regression, metrics=metrics)\n",
    "        print(results_test)\n",
    "        print(results_valid)\n",
    "\n",
    "    model = model_builder(model_name, hyperparams, regression)\n",
    "    results_test, results_valid = train_and_test(model, X_train, y_train, X_test, y_test, X_valid, y_valid, regression=regression, metrics=metrics)\n",
    "    print(results_test)\n",
    "    print(results_valid)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-rms_score': 1.1130731457434249, 'mean-mean_squared_error': 1.2389318277751633, 'mean-mean_absolute_error': 0.8172035240993828, 'mean-r2_score': 0.2382906374873478}\n",
      "{'mean-rms_score': 1.4077217744314252, 'mean-mean_squared_error': 1.9816805942083602, 'mean-mean_absolute_error': 1.106048857805556, 'mean-r2_score': 0.4949199589861579}\n",
      "{'rmse': 1.1031047949108816, 'mse': 1.2168401885553781, 'mae': 0.8087597581903951, 'r2': 0.25187282825016}\n",
      "{'rmse': 1.4077956054374614, 'mse': 1.9818884666890284, 'mae': 1.124339058361588, 'r2': 0.4948669775716109}\n",
      "{'mean-rms_score': 127047180.50147216, 'mean-mean_squared_error': 1.6140986073373646e+16, 'mean-mean_absolute_error': 92728804.97208469, 'mean-r2_score': -9923661606428792.0}\n",
      "{'mean-rms_score': 173583140.66615406, 'mean-mean_squared_error': 3.0131106723525824e+16, 'mean-mean_absolute_error': 128864218.27741078, 'mean-r2_score': -7679653655684303.0}\n",
      "{'rmse': 127047180.50147212, 'mse': 1.6140986073373638e+16, 'mae': 92728804.97208469, 'r2': -9923661606428788.0}\n",
      "{'rmse': 173583140.66615397, 'mse': 3.0131106723525796e+16, 'mae': 128864218.27741067, 'r2': -7679653655684295.0}\n",
      "{'rmse': 1.0078175984283004, 'mse': 1.015696311701787, 'mae': 0.8335692238833451, 'r2': 0.37553836882038505}\n",
      "{'rmse': 1.600047784881914, 'mse': 2.5601529139055197, 'mae': 1.3621434896439184, 'r2': 0.34748206015830396}\n",
      "{'mean-rms_score': 1.0913138642938682, 'mean-mean_squared_error': 1.1909659504000156, 'mean-mean_absolute_error': 0.7919902553129954, 'mean-r2_score': 0.2677806038105103}\n",
      "{'mean-rms_score': 1.4599508113682786, 'mean-mean_squared_error': 2.1314563716148953, 'mean-mean_absolute_error': 1.16286929059992, 'mean-r2_score': 0.4567459182166903}\n",
      "{'rmse': 1.0877594703810831, 'mse': 1.1832206654037345, 'mae': 0.7891531252660664, 'r2': 0.27254249301598044}\n",
      "{'rmse': 1.4702739582649842, 'mse': 2.1617055123521847, 'mae': 1.177679799697791, 'r2': 0.44903618068942397}\n",
      "{'mean-rms_score': 1.130792414461001, 'mean-mean_squared_error': 1.2786914846025406, 'mean-mean_absolute_error': 0.8244696695108115, 'mean-r2_score': 0.21384594878313645}\n",
      "{'mean-rms_score': 1.4513757785636463, 'mean-mean_squared_error': 2.106491650601231, 'mean-mean_absolute_error': 1.0910949760861206, 'mean-r2_score': 0.46310879140136607}\n",
      "{'rmse': 1.130792414461001, 'mse': 1.2786914846025406, 'mae': 0.8244696695108115, 'r2': 0.21384594878313645}\n",
      "{'rmse': 1.4513757785636463, 'mse': 2.106491650601231, 'mae': 1.0910949760861206, 'r2': 0.46310879140136607}\n"
     ]
    }
   ],
   "source": [
    "### Row by row\n",
    "data = {\"model\": [], \"set\": []}\n",
    "if regression:\n",
    "    for metric in [\"rmse\", \"mse\", \"mae\", \"r2\"]:\n",
    "        data[metric] = []\n",
    "else:\n",
    "    for metric in [\"roc_auc\", \"accuracy\", \"precision\", \"recall\", \"f1\"]:\n",
    "        data[metric] = []\n",
    "\n",
    "results_df = pd.DataFrame(data)\n",
    "for model_name, hyperparams in models_with_parameters:\n",
    "    #print(model_name)\n",
    "\n",
    "    model = model_builder(model_name, hyperparams, regression)\n",
    "    if model_name != \"nn\":\n",
    "        temp_test, temp_valid = benchmark_train_and_test(model, X_train, y_train, X_test, y_test, X_valid, y_valid, regression=regression, metrics=metrics)\n",
    "        print(temp_test)\n",
    "        print(temp_valid)\n",
    "\n",
    "        results_test = {}\n",
    "        results_valid = {}\n",
    "\n",
    "        for index, key in enumerate(temp_test.keys()):\n",
    "            if key[:5] == \"mean-\":\n",
    "                key = key[5:]\n",
    "            if key[-6:] == \"_score\":\n",
    "                key = key[:-6]\n",
    "            results_test[key] = temp_test[list(temp_test.keys())[index]]\n",
    "\n",
    "        results_test[\"model\"] = model_name\n",
    "        results_test[\"set\"] = \"test\"\n",
    "        results_df.loc[len(results_df)] = results_test\n",
    "\n",
    "\n",
    "        for index, key in enumerate(temp_valid.keys()):\n",
    "            if key[:5] == \"mean-\":\n",
    "                key = key[5:]\n",
    "            if key[-6:] == \"_score\":\n",
    "                key = key[:-6]\n",
    "            results_valid[key] = temp_valid[list(temp_valid.keys())[index]]\n",
    "\n",
    "        results_valid[\"model\"] = model_name\n",
    "        results_valid[\"set\"] = \"valid\"\n",
    "        results_df.loc[len(results_df)] = results_valid\n",
    "\n",
    "    model = model_builder(model_name, hyperparams, regression)\n",
    "    results_test, results_valid = train_and_test(model, X_train, y_train, X_test, y_test, X_valid, y_valid, regression=regression, metrics=metrics)\n",
    "    print(results_test)\n",
    "    print(results_valid)\n",
    "    results_test[\"model\"] = model_name\n",
    "    results_test[\"set\"] = \"test\"\n",
    "    results_df.loc[len(results_df)] = results_test\n",
    "    results_valid[\"model\"] = model_name\n",
    "    results_valid[\"set\"] = \"valid\"\n",
    "    results_df.loc[len(results_df)] = results_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>set</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.382906e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>valid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.949200e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>test</td>\n",
       "      <td>1.103105e+00</td>\n",
       "      <td>1.216840e+00</td>\n",
       "      <td>8.087598e-01</td>\n",
       "      <td>2.518728e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>valid</td>\n",
       "      <td>1.407796e+00</td>\n",
       "      <td>1.981888e+00</td>\n",
       "      <td>1.124339e+00</td>\n",
       "      <td>4.948670e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lr</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.923662e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lr</td>\n",
       "      <td>valid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.679654e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lr</td>\n",
       "      <td>test</td>\n",
       "      <td>1.270472e+08</td>\n",
       "      <td>1.614099e+16</td>\n",
       "      <td>9.272880e+07</td>\n",
       "      <td>-9.923662e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lr</td>\n",
       "      <td>valid</td>\n",
       "      <td>1.735831e+08</td>\n",
       "      <td>3.013111e+16</td>\n",
       "      <td>1.288642e+08</td>\n",
       "      <td>-7.679654e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nn</td>\n",
       "      <td>test</td>\n",
       "      <td>1.007818e+00</td>\n",
       "      <td>1.015696e+00</td>\n",
       "      <td>8.335692e-01</td>\n",
       "      <td>3.755384e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nn</td>\n",
       "      <td>valid</td>\n",
       "      <td>1.600048e+00</td>\n",
       "      <td>2.560153e+00</td>\n",
       "      <td>1.362143e+00</td>\n",
       "      <td>3.474821e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gb</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.677806e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gb</td>\n",
       "      <td>valid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.567459e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gb</td>\n",
       "      <td>test</td>\n",
       "      <td>1.087759e+00</td>\n",
       "      <td>1.183221e+00</td>\n",
       "      <td>7.891531e-01</td>\n",
       "      <td>2.725425e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gb</td>\n",
       "      <td>valid</td>\n",
       "      <td>1.470274e+00</td>\n",
       "      <td>2.161706e+00</td>\n",
       "      <td>1.177680e+00</td>\n",
       "      <td>4.490362e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sv</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.138459e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sv</td>\n",
       "      <td>valid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.631088e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sv</td>\n",
       "      <td>test</td>\n",
       "      <td>1.130792e+00</td>\n",
       "      <td>1.278691e+00</td>\n",
       "      <td>8.244697e-01</td>\n",
       "      <td>2.138459e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sv</td>\n",
       "      <td>valid</td>\n",
       "      <td>1.451376e+00</td>\n",
       "      <td>2.106492e+00</td>\n",
       "      <td>1.091095e+00</td>\n",
       "      <td>4.631088e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model    set          rmse           mse           mae            r2\n",
       "0     rf   test           NaN           NaN           NaN  2.382906e-01\n",
       "1     rf  valid           NaN           NaN           NaN  4.949200e-01\n",
       "2     rf   test  1.103105e+00  1.216840e+00  8.087598e-01  2.518728e-01\n",
       "3     rf  valid  1.407796e+00  1.981888e+00  1.124339e+00  4.948670e-01\n",
       "4     lr   test           NaN           NaN           NaN -9.923662e+15\n",
       "5     lr  valid           NaN           NaN           NaN -7.679654e+15\n",
       "6     lr   test  1.270472e+08  1.614099e+16  9.272880e+07 -9.923662e+15\n",
       "7     lr  valid  1.735831e+08  3.013111e+16  1.288642e+08 -7.679654e+15\n",
       "8     nn   test  1.007818e+00  1.015696e+00  8.335692e-01  3.755384e-01\n",
       "9     nn  valid  1.600048e+00  2.560153e+00  1.362143e+00  3.474821e-01\n",
       "10    gb   test           NaN           NaN           NaN  2.677806e-01\n",
       "11    gb  valid           NaN           NaN           NaN  4.567459e-01\n",
       "12    gb   test  1.087759e+00  1.183221e+00  7.891531e-01  2.725425e-01\n",
       "13    gb  valid  1.470274e+00  2.161706e+00  1.177680e+00  4.490362e-01\n",
       "14    sv   test           NaN           NaN           NaN  2.138459e-01\n",
       "15    sv  valid           NaN           NaN           NaN  4.631088e-01\n",
       "16    sv   test  1.130792e+00  1.278691e+00  8.244697e-01  2.138459e-01\n",
       "17    sv  valid  1.451376e+00  2.106492e+00  1.091095e+00  4.631088e-01"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
