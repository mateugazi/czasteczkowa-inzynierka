{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from deepchem.molnet import load_bace_classification, load_bace_regression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = False\n",
    "deepchem_preprocessing = True ### Use preprocessing used in the benchmark file?\n",
    "scaffold_split = False ### Submit the scaffold list as the basis?\n",
    "descriptors = False\n",
    "fingerprints = False\n",
    "dataset_features = True ### BACE built-in features\n",
    "models = ['rf']\n",
    "\n",
    "hyperparams = {\n",
    "  \"bootstrap\": True,\n",
    "  \"criterion\": \"entropy\",\n",
    "  \"min_samples_split\": 32,\n",
    "  \"n_estimators\": 30\n",
    "}\n",
    "\n",
    "dataset_path = r\"C:\\Users\\wojci\\Documents\\GitHub\\czasteczkowa-inzynierka\\experiments\\BACE\\bace.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<deepchem.trans.transformers.BalancingTransformer object at 0x0000028283D11610>]\n",
      "<DiskDataset X.shape: (152, 1024), y.shape: (152, 1), w.shape: (152, 1), ids: ['O1CCC(CC1)CNC(=O)C(Cc1cc2cc(ccc2nc1N)-c1ccccc1C)C'\n",
      " 'O1c2ncc(cc2C([NH2+]CC(O)C2NC(=O)C=3C=CC(=O)N(CCCCc4cc(C2)ccc4)C=3)CC12CCC2)CC(C)(C)C'\n",
      " 'O1c2ncc(cc2C([NH2+]CC(O)C(NC(=O)COC)Cc2cc(ccc2)-c2occn2)CC12CCC2)CC(C)(C)C'\n",
      " ...\n",
      " 'Fc1c2c(ccc1)[C@@]([NH+]=C2N)(C=1C=C(C)C(=O)N(C=1)CC)c1cc(ccc1)-c1cc(cnc1)C#CC'\n",
      " 'S(=O)(=O)(CCCCC)C[C@@H](NC(=O)c1cccnc1)C(=O)N[C@H]([C@H](O)C[NH2+]Cc1cc(ccc1)CC)Cc1cc(F)cc(F)c1'\n",
      " 'O1CC[C@@H](NC(=O)[C@@H](Cc2cc3cc(ccc3nc2N)-c2ccccc2C)C)CC1(C)C'], task_names: ['Class']>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if deepchem_preprocessing:\n",
    "    featurizer = 'ECFP'\n",
    "    splitter = 'scaffold' ### Others? RandomSpliter?\n",
    "    tasks, all_dataset, transformers = load_bace_classification(\n",
    "                                            featurizer=featurizer, splitter=splitter, reload=False)\n",
    "    \n",
    "    print(transformers)\n",
    "    \n",
    "    train_set, valid_set, test_set = all_dataset\n",
    "\n",
    "    print(test_set)\n",
    "\n",
    "else:\n",
    "    ### Read csv dataset\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df.drop_duplicates('mol')\n",
    "    df = df.dropna()\n",
    "    df.drop(['CID', 'canvasUID'], axis=1, inplace=True)\n",
    "    if regression:\n",
    "        df['Target'] = df['pIC50']\n",
    "        df.drop('Class', axis=1, inplace=True)\n",
    "        df.drop('pIC50', axis=1, inplace=True)\n",
    "    else:\n",
    "        df['Target'] = df['Class']\n",
    "        df.drop('Class', axis=1, inplace=True)\n",
    "        df.drop('pIC50', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    ### Create dataframe with only molecules and targets\n",
    "    ### Calculate descriptors and/or fingerprints or use submitted parameters\n",
    "    \n",
    "    #if descriptors:\n",
    "        \n",
    "\n",
    "    #if fingerprints:\n",
    "\n",
    "\n",
    "    if dataset_features:\n",
    "        X = df.drop(['Target', 'mol'], axis=1)\n",
    "        y = df[['Target', 'Model']]\n",
    "        \n",
    "        X_train = X[X['Model'] == 'Train']\n",
    "        y_train = y[y['Model'] == 'Train']\n",
    "        X_test = X[X['Model'] == 'Test']\n",
    "        y_test = y[y['Model'] == 'Test']\n",
    "        X_valid = X[X['Model'] == 'Valid']\n",
    "        y_valid = y[y['Model'] == 'Valid']\n",
    "        \n",
    "        X_train.drop('Model', axis=1, inplace=True)\n",
    "        y_train.drop('Model', axis=1, inplace=True)\n",
    "        X_test.drop('Model', axis=1, inplace=True)\n",
    "        y_test.drop('Model', axis=1, inplace=True)\n",
    "        X_valid.drop('Model', axis=1, inplace=True)\n",
    "        y_valid.drop('Model', axis=1, inplace=True)\n",
    "            \n",
    "\n",
    "        train_set = dc.data.DiskDataset.from_numpy(X_train, y=y_train)\n",
    "        test_set = dc.data.DiskDataset.from_numpy(X_test, y=y_test)\n",
    "        valid_set = dc.data.DiskDataset.from_numpy(X_valid, y=y_valid)\n",
    "\n",
    "        print(train_set.y)\n",
    "\n",
    "    #X_train = dc.data.DiskDataset.from_numpy(X_train)\n",
    "    #y_train = dc.data.DiskDataset.from_numpy(y_train)\n",
    "    #X_test = dc.data.DiskDataset.from_numpy(X_test)\n",
    "    #y_test = dc.data.DiskDataset.from_numpy(y_test)\n",
    "    #X_valid = dc.data.DiskDataset.from_numpy(X_valid)\n",
    "    #y_valid = dc.data.DiskDataset.from_numpy(y_valid)\n",
    "\n",
    "\n",
    "\n",
    "    ### Clean dataset\n",
    "\n",
    "    ### Translate SMILES into features through fingerprints or descriptors\n",
    "\n",
    "    ### Split into train, test and validation steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model_builder(model_dir, hyperparams, tasks):\n",
    "        sklearn_model = RandomForestClassifier(n_estimators=hyperparams[\"n_estimators\"],\n",
    "            min_samples_split=hyperparams[\"min_samples_split\"], criterion=hyperparams[\"criterion\"],\n",
    "            bootstrap=hyperparams[\"bootstrap\"])\n",
    "\n",
    "        return dc.models.SklearnModel(sklearn_model, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "if regression:\n",
    "    model = RandomForestRegressor(n_estimators=hyperparams[\"n_estimators\"],\n",
    "                                    min_samples_split=hyperparams[\"min_samples_split\"],\n",
    "                                    criterion=hyperparams[\"criterion\"],\n",
    "                                    bootstrap=hyperparams[\"bootstrap\"])\n",
    "else:\n",
    "    model = RandomForestClassifier(n_estimators=hyperparams[\"n_estimators\"],\n",
    "                                    min_samples_split=hyperparams[\"min_samples_split\"],\n",
    "                                    criterion=hyperparams[\"criterion\"],\n",
    "                                    bootstrap=hyperparams[\"bootstrap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695994895229944\n",
      "0.2840909090909091\n",
      "0.7013862354613397\n",
      "0.7954545454545454\n",
      "0.684819932038291\n",
      "0.2840909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojci\\AppData\\Local\\Temp\\ipykernel_4884\\1852718092.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n",
      "C:\\Users\\wojci\\AppData\\Local\\Temp\\ipykernel_4884\\1852718092.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n",
      "C:\\Users\\wojci\\AppData\\Local\\Temp\\ipykernel_4884\\1852718092.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_predicted = model.predict(X_test)\n",
    "    y_valid_predicted = model.predict(X_valid)\n",
    "\n",
    "    roc_auc_test = roc_auc_score(y_test, y_test_predicted)\n",
    "    roc_auc_valid = roc_auc_score(y_valid, y_valid_predicted)\n",
    "\n",
    "    print(roc_auc_test)\n",
    "    print(roc_auc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "<DiskDataset X.shape: (1210, 1024), y.shape: (1210, 1), w.shape: (1210, 1), task_names: ['Class']>\n",
      "<DiskDataset X.shape: (1210, 1024), y.shape: (1210, 1), w.shape: (1210, 1), task_names: ['Class']>\n"
     ]
    }
   ],
   "source": [
    "print(train_set.X.dtype)\n",
    "print(train_set.y.dtype)\n",
    "\n",
    "alt_train_set = dc.data.DiskDataset.from_numpy(X=train_set.X, y=train_set.y, w=train_set.w, ids=train_set.ids, tasks=['Class'])\n",
    "print(train_set)\n",
    "print(alt_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean-roc_auc_score': 0.8364130434782608}\n",
      "{'mean-roc_auc_score': 0.7308990760483298}\n",
      "{'mean-roc_auc_score': 0.8559782608695653}\n",
      "{'mean-roc_auc_score': 0.7277896233120114}\n",
      "{'mean-roc_auc_score': 0.8472826086956522}\n",
      "{'mean-roc_auc_score': 0.7392501776830136}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = dc.models.SingletaskToMultitask(\n",
    "        tasks, partial(rf_model_builder, hyperparams=hyperparams, tasks=tasks))\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "\n",
    "for i in range(3):\n",
    "    model.fit(alt_train_set)\n",
    "\n",
    "    test_metric = model.evaluate(test_set, [metric], transformers)\n",
    "    valid_metric = model.evaluate(valid_set, [metric], transformers)\n",
    "\n",
    "    print(test_metric)\n",
    "    print(valid_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
