{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import (StratifiedKFold, KFold,\n",
    "                                     cross_val_score, train_test_split)\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "N_SPLITS = 2\n",
    "RANDOM_STATE = 148260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateMorganFingerprint(mol):\n",
    "    mfpgen = AllChem.GetMorganGenerator(radius=2,fpSize=2048)\n",
    "    fingerprint = np.array([mfpgen.GetFingerprintAsNumPy(x) for x in mol])\n",
    "    fingerprint = pd.DataFrame(fingerprint, columns = ['mfp'+str(i) for i in range(fingerprint.shape[1])])\n",
    "    return fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateDescriptors(mol):\n",
    "    calc = Calculator(descriptors, ignore_3D=False)\n",
    "    X_mordred = calc.pandas(mol, nproc=1)\n",
    "    X_mordred = X_mordred.select_dtypes(['number'])\n",
    "    #normalize\n",
    "    X_mordred = (X_mordred-X_mordred.min())/(X_mordred.max()-X_mordred.min())\n",
    "    #drop columns wth low std\n",
    "    X_mordred = X_mordred.loc[:,X_mordred.std()>0.01]\n",
    "    return X_mordred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDatasetCSV(path, threshold=7.0, regression = False):\n",
    "    df = pd.read_csv(path)\n",
    "    df['molecule_from_smiles'] = df['smiles'].apply(Chem.MolFromSmiles)\n",
    "    df['smiles'] = df['smiles'].map(lambda x: Chem.MolToSmiles(Chem.MolFromSmiles(x)))\n",
    "    df.drop_duplicates('smiles')\n",
    "    df = df.dropna()\n",
    "    if regression:\n",
    "        df['Target'] = df['pIC50']\n",
    "    else:\n",
    "        df['Target'] = df['pIC50'] > threshold\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, approach = 'desc', split = 0.7):\n",
    "    #TODO: support for different approaches - if applicable\n",
    "    if approach == 'desc':\n",
    "        X = CalculateDescriptors(df['molecule_from_smiles'])\n",
    "    else:\n",
    "        X = CalculateMorganFingerprint(df['molecule_from_smiles'])\n",
    "    y = df[\"Target\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1-split), random_state=42)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf(X, y, n_estimators, max_depth, min_samples_split, min_samples_leaf, regression=False):\n",
    "    if regression:\n",
    "        name = \"RandomForestRegressor\"\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "        cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        name = \"RandomForestClassifier\"\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'accuracy'\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    mean_accuracy = scores.mean()\n",
    "    return (f\"{name}-{n_estimators}-{max_depth}-{min_samples_split}-{min_samples_leaf}; {mean_accuracy:.4f}\")\n",
    "\n",
    "def run_lr(X, y, C, penalty, solver, regression=False):\n",
    "    if regression:\n",
    "        name = \"LinearRegression\"\n",
    "        model = LinearRegression()\n",
    "        cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        name = \"LogisticRegression\"\n",
    "        model = LogisticRegression(C=C, penalty=penalty, solver=solver)\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'accuracy'\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    mean_accuracy = scores.mean()\n",
    "    return (f\"{name}-{C}-{penalty}-{solver}; {mean_accuracy:.4f}\")\n",
    "\n",
    "def run_nn(X, y, hidden_layer_sizes, activation, alpha, max_iter, regression=False):\n",
    "    if regression:\n",
    "        name = \"MLPRegressor\"\n",
    "        model = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, activation=activation, alpha=alpha, max_iter=max_iter)\n",
    "        cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        name = \"MLPClassifier\"\n",
    "        model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, alpha=alpha, max_iter=max_iter)\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'accuracy'\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    mean_accuracy = scores.mean()\n",
    "    return (f\"{name}-{hidden_layer_sizes}-{activation}-{alpha}-{max_iter}; {mean_accuracy:.4f}\")\n",
    "\n",
    "def run_gb(X, y, n_estimators, learning_rate, regression=False):\n",
    "    if regression:\n",
    "        name = \"GradientBoostingRegressor\"\n",
    "        model = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "        cv = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    else:\n",
    "        name = \"GradientBoostingClassifier\"\n",
    "        model = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "        cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "        scoring = 'accuracy'\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)\n",
    "    mean_accuracy = scores.mean()\n",
    "    return (f\"{name}-{n_estimators}-{learning_rate}; {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(X, y, regression=False):\n",
    "    results = []\n",
    "    param_grid_rf={\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    param_combinations = list(product(*param_grid_rf.values()))\n",
    "    for combination in param_combinations:\n",
    "        n, m, s, l = combination\n",
    "        results.append(run_rf(X, y, n, m, s, l, regression))\n",
    "    param_grid_lr = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    }\n",
    "    if regression:\n",
    "        param_grid_lr = {\n",
    "            'C': [0.001],\n",
    "            'penalty': ['l1'],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    param_combinations = list(product(*param_grid_lr.values()))\n",
    "    for combination in param_combinations:\n",
    "        C, p, s = combination\n",
    "        results.append(run_lr(X, y, C, p, s, regression))\n",
    "    param_grid_mlp = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'max_iter': [200, 500, 1000]\n",
    "    }\n",
    "    param_combinations = list(product(*param_grid_mlp.values()))\n",
    "    for combination in param_combinations:\n",
    "        h, ac, a, i = combination\n",
    "        results.append(run_nn(X, y, h, ac, a, i, regression))\n",
    "    param_grid_gb={\n",
    "        'n_estimators': [10, 100, 200], \n",
    "        'learning_rate': [0.1,0.5,1.0,2.0]\n",
    "    }\n",
    "    param_combinations = list(product(*param_grid_gb.values()))\n",
    "    for combination in param_combinations:\n",
    "        n, lr = combination\n",
    "        results.append(run_gb(X, y, n, lr, regression))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classification = LoadDatasetCSV(\"data\\processed\\simple_input_data.csv\")\n",
    "data_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regression = LoadDatasetCSV(\"data\\processed\\simple_input_data.csv\", regression=True)\n",
    "data_regression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_desc_classification, y_train_desc_classification, X_test_desc_classification, y_test_desc_classification = split_data(data_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_desc_regression, y_train_desc_regression, X_test_desc_regression, y_test_desc_regression = split_data(data_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fp_classification, y_train_fp_classification, X_test_fp_classification, y_test_fp_classification = split_data(data_classification, approach = 'fp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fp_regression, y_train_fp_regression, X_test_fp_regression, y_test_fp_regression = split_data(data_regression, approach = 'fp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled-PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - test out different PCA parameters\n",
    "\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_experimental = sc.fit_transform(pd.concat([X_train_desc_classification, X_test_desc_classification]))\n",
    "X_experimental = pca.fit_transform(X_experimental)\n",
    "y_experimental = pd.concat([y_train_desc_classification, y_test_desc_classification])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all(X_experimental, y_experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = [tuple(item.split('; ')) for item in results]\n",
    "\n",
    "df = pd.DataFrame(data_tuples, columns=['Classifier', 'Accuracy'])\n",
    "\n",
    "df.to_csv(\"results_classification_descriptors_scpca.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_experimental = sc.fit_transform(pd.concat([X_train_desc_classification, X_test_desc_classification]))\n",
    "y_experimental = pd.concat([y_train_desc_classification, y_test_desc_classification])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all(X_experimental, y_experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = [tuple(item.split('; ')) for item in results]\n",
    "\n",
    "df = pd.DataFrame(data_tuples, columns=['Classifier', 'Accuracy'])\n",
    "\n",
    "df.to_csv(\"results_classification_descriptors_sc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled-PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - test out different PCA parameters\n",
    "\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_experimental = sc.fit_transform(pd.concat([X_train_desc_regression, X_test_desc_regression]))\n",
    "X_experimental = pca.fit_transform(X_experimental)\n",
    "y_experimental = pd.concat([y_train_desc_regression, y_test_desc_regression])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all(X_experimental, y_experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = [tuple(item.split('; ')) for item in results]\n",
    "\n",
    "df = pd.DataFrame(data_tuples, columns=['Classifier', 'Accuracy'])\n",
    "\n",
    "df.to_csv(\"results_regression_descriptors_scpca.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_experimental = sc.fit_transform(pd.concat([X_train_desc_regression, X_test_desc_regression]))\n",
    "y_experimental = pd.concat([y_train_desc_regression, y_test_desc_regression])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all(X_experimental, y_experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = [tuple(item.split('; ')) for item in results]\n",
    "\n",
    "df = pd.DataFrame(data_tuples, columns=['Classifier', 'Accuracy'])\n",
    "\n",
    "df.to_csv(\"results_regression_descriptors_sc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled-PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - test out different PCA parameters\n",
    "\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_experimental = sc.fit_transform(pd.concat([X_train_fp_classification, X_test_fp_classification]))\n",
    "X_experimental = pca.fit_transform(X_experimental)\n",
    "y_experimental = pd.concat([y_train_fp_classification, y_test_fp_classification])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all(X_experimental, y_experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = [tuple(item.split('; ')) for item in results]\n",
    "\n",
    "df = pd.DataFrame(data_tuples, columns=['Classifier', 'Accuracy'])\n",
    "\n",
    "df.to_csv(\"results_classification_fingerprints_scpca.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_experimental = sc.fit_transform(pd.concat([X_train_fp_classification, X_test_fp_classification]))\n",
    "y_experimental = pd.concat([y_train_fp_classification, y_test_fp_classification])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all(X_experimental, y_experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = [tuple(item.split('; ')) for item in results]\n",
    "\n",
    "df = pd.DataFrame(data_tuples, columns=['Classifier', 'Accuracy'])\n",
    "\n",
    "df.to_csv(\"results_classification_fingerprints_sc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled-PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - test out different PCA parameters\n",
    "\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_experimental = sc.fit_transform(pd.concat([X_train_fp_regression, X_test_fp_regression]))\n",
    "X_experimental = pca.fit_transform(X_experimental)\n",
    "y_experimental = pd.concat([y_train_fp_regression, y_test_fp_regression])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all(X_experimental, y_experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = [tuple(item.split('; ')) for item in results]\n",
    "\n",
    "df = pd.DataFrame(data_tuples, columns=['Classifier', 'Accuracy'])\n",
    "\n",
    "df.to_csv(\"results_regression_fingerprints_scpca.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_experimental = sc.fit_transform(pd.concat([X_train_fp_regression, X_test_fp_regression]))\n",
    "y_experimental = pd.concat([y_train_fp_regression, y_test_fp_regression])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_all(X_experimental, y_experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = [tuple(item.split('; ')) for item in results]\n",
    "\n",
    "df = pd.DataFrame(data_tuples, columns=['Classifier', 'Accuracy'])\n",
    "\n",
    "df.to_csv(\"results_regression_fingerprints_sc.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
